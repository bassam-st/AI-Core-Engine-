# core/context_manager.py â€” Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø°ÙƒÙŠ ÙˆØ§Ù„Ù…ØªÙ‚Ø¯Ù…
from __future__ import annotations
import logging
import re
import json
import time
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logger = logging.getLogger(__name__)

class ContextType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
    CONVERSATION = "conversation"
    USER_PREFERENCE = "user_preference"
    DOMAIN_KNOWLEDGE = "domain_knowledge"
    TEMPORAL = "temporal"
    GEOGRAPHICAL = "geographical"
    TECHNICAL = "technical"
    EMOTIONAL = "emotional"

class PriorityLevel(Enum):
    """Ù…Ø³ØªÙˆÙŠØ§Øª Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø³ÙŠØ§Ù‚"""
    CRITICAL = 5
    HIGH = 4
    MEDIUM = 3
    LOW = 2
    BACKGROUND = 1

@dataclass
class ContextItem:
    """Ø¹Ù†ØµØ± Ø³ÙŠØ§Ù‚ ÙØ±Ø¯ÙŠ"""
    id: str
    type: ContextType
    content: Dict[str, Any]
    priority: PriorityLevel
    created_at: float
    expires_at: Optional[float] = None
    source: str = "system"
    confidence: float = 1.0
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
        if self.expires_at is None:
            # Ø§ÙØªØ±Ø§Ø¶ÙŠ: Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¨Ø¹Ø¯ Ø³Ø§Ø¹Ø© Ù„Ù„Ø³ÙŠØ§Ù‚Ø§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            self.expires_at = self.created_at + 3600

    def is_expired(self) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù†ØªÙ‡Ø§Ø¡ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø³ÙŠØ§Ù‚"""
        if self.expires_at is None:
            return False
        return time.time() > self.expires_at

    def to_dict(self) -> Dict[str, Any]:
        """ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù‚Ø§Ù…ÙˆØ³"""
        return {
            "id": self.id,
            "type": self.type.value,
            "content": self.content,
            "priority": self.priority.value,
            "created_at": self.created_at,
            "expires_at": self.expires_at,
            "source": self.source,
            "confidence": self.confidence,
            "metadata": self.metadata
        }

class ContextManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… - ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
    
    def __init__(self, session_id: str = "default"):
        self.session_id = session_id
        self.context_store: Dict[str, ContextItem] = {}
        self.conversation_history: List[Dict] = []
        self.user_profile: Dict[str, Any] = {}
        self.domain_context: Dict[str, Any] = {}
        self.temporal_context: Dict[str, Any] = {}
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø³ÙŠØ§Ù‚
        self.max_conversation_history = 50
        self.max_context_items = 100
        self.context_ttl = 3600  # Ø«Ø§Ù†ÙŠØ© ÙˆØ§Ø­Ø¯Ø©
        
        # Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙƒØ´Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
        self.domain_patterns = {
            "programming": [r"ÙƒÙˆØ¯", r"Ø¨Ø±Ù…Ø¬Ø©", r"Ø¨Ø§ÙŠØ«ÙˆÙ†", r"Ø¬Ø§ÙØ§", r"html", r"css", r"Ø³ÙƒØ±ÙŠØ¨Øª"],
            "technology": [r"ØªÙ‚Ù†ÙŠØ©", r"ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§", r"Ø°ÙƒØ§Ø¡", r"Ø¢Ù„Ø©", r"Ø¨ÙŠØ§Ù†Ø§Øª", r"Ø³ÙŠØ±ÙØ±"],
            "science": [r"Ø¹Ù„Ù…", r"Ø¨Ø­Ø«", r"Ø¯Ø±Ø§Ø³Ø©", r"Ù†Ø¸Ø±ÙŠØ©", r"ØªØ¬Ø±Ø¨Ø©"],
            "business": [r"ØªØ¬Ø§Ø±Ø©", r"Ø´Ø±ÙƒØ©", r"Ø³ÙˆÙ‚", Ø±"Ø±Ø¨Ø­", Ø±"Ø§Ø³ØªØ«Ù…Ø§Ø±"],
            "education": [r"ØªØ¹Ù„Ù…", r"Ø¯Ø±Ø§Ø³Ø©", Ø±"Ù…Ø¯Ø±Ø³Ø©", Ø±"Ø¬Ø§Ù…Ø¹Ø©", Ø±"ØªØ¹Ù„ÙŠÙ…"]
        }
        
        logger.info(f"ğŸš€ ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„Ø³ÙŠØ§Ù‚ Ù„Ù„Ø¬Ù„Ø³Ø©: {session_id}")

    def add_conversation_turn(self, user_message: str, bot_response: str, metadata: Dict = None):
        """Ø¥Ø¶Ø§ÙØ© Ø¯ÙˆØ± Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯ Ø¥Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ®"""
        turn = {
            "user": user_message,
            "bot": bot_response,
            "timestamp": time.time(),
            "metadata": metadata or {}
        }
        
        self.conversation_history.append(turn)
        
        # Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ù…Ø¹Ù‚ÙˆÙ„ Ù„Ù„Ø³Ø¬Ù„
        if len(self.conversation_history) > self.max_conversation_history:
            self.conversation_history.pop(0)
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³ÙŠØ§Ù‚ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        self._auto_update_context(user_message, bot_response)
        
        logger.debug(f"ğŸ“ ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø¯ÙˆØ± Ù…Ø­Ø§Ø¯Ø«Ø© ({len(self.conversation_history)} Ø£Ø¯ÙˆØ§Ø±)")

    def _auto_update_context(self, user_message: str, bot_response: str):
        """Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ø³ÙŠØ§Ù‚ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        
        # ÙƒØ´Ù Ø§Ù„Ù…Ø¬Ø§Ù„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
        detected_domains = self._detect_domains(user_message)
        for domain in detected_domains:
            self.update_domain_context(domain, {"last_mentioned": time.time()})
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙØ¶ÙŠÙ„Ø§Øª
        preferences = self._extract_preferences(user_message)
        for pref_key, pref_value in preferences.items():
            self.update_user_preference(pref_key, pref_value)
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ
        emotional_context = self._analyze_emotional_context(user_message, bot_response)
        if emotional_context:
            self.add_context_item(
                ContextType.EMOTIONAL,
                emotional_context,
                PriorityLevel.MEDIUM
            )

    def _detect_domains(self, text: str) -> List[str]:
        """ÙƒØ´Ù Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù…Ù† Ø§Ù„Ù†Øµ"""
        detected = []
        text_lower = text.lower()
        
        for domain, patterns in self.domain_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_lower):
                    detected.append(domain)
                    break
        
        return detected

    def _extract_preferences(self, text: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø§Ù„Ù†Øµ"""
        preferences = {}
        
        # ÙƒØ´Ù Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙØµÙŠÙ„ Ø§Ù„Ù…ÙØ¶Ù„
        detail_indicators = {
            "high_detail": [r"Ø¨Ø§Ù„ØªÙØµÙŠÙ„", r"Ø´Ø±Ø­ Ù…ÙØµÙ„", r"ØªÙØµÙŠÙ„ÙŠ", r"ÙƒØ§Ù…Ù„"],
            "low_detail": [r"Ø¨Ø§Ø®ØªØµØ§Ø±", r"Ù…Ù„Ø®Øµ", Ø±"Ø¨Ø´ÙƒÙ„ Ù…Ø®ØªØµØ±", Ø±"Ø³Ø±ÙŠØ¹"]
        }
        
        for level, indicators in detail_indicators.items():
            for indicator in indicators:
                if re.search(indicator, text.lower()):
                    preferences["preferred_detail_level"] = level
                    break
        
        # ÙƒØ´Ù Ù†ÙˆØ¹ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…ÙØ¶Ù„Ø©
        help_indicators = {
            "practical": [r"Ø¹Ù…Ù„ÙŠ", r"ØªØ·Ø¨ÙŠÙ‚ÙŠ", Ø±"Ù…Ø«Ø§Ù„", Ø±"ØªÙ†ÙÙŠØ°"],
            "theoretical": [r"Ù†Ø¸Ø±ÙŠ", Ø±"Ù…ÙÙ‡ÙˆÙ…", Ø±"Ø´Ø±Ø­", Ø±"ÙÙ‡Ù…"]
        }
        
        for help_type, indicators in help_indicators.items():
            for indicator in indicators:
                if re.search(indicator, text.lower()):
                    preferences["preferred_help_type"] = help_type
                    break
        
        return preferences

    def _analyze_emotional_context(self, user_message: str, bot_response: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ"""
        emotional_indicators = {
            "frustration": [r"Ù„Ø§ Ø£ÙÙ‡Ù…", r"Ù„Ù…Ø§Ø°Ø§", Ø±"Ù…Ø´ÙƒÙ„Ø©", Ø±"ØµØ¹Ø¨", Ø±"Ù…Ø¹Ù‚Ø¯"],
            "satisfaction": [r"Ø´ÙƒØ±Ø§Ù‹", Ø±"Ù…Ù…ØªØ§Ø²", Ø±"Ø±Ø§Ø¦Ø¹", Ø±"Ø¬Ù…ÙŠÙ„", Ø±"Ø£Ø­Ø³Ù†Øª"],
            "urgency": [r"Ø¨Ø³Ø±Ø¹Ø©", Ø±"Ø¹Ø§Ø¬Ù„", Ø±"Ø§Ù„Ø¢Ù†", Ø±"ÙÙˆØ±ÙŠ"],
            "confusion": [r"Ù…Ø§Ø°Ø§", Ø±"ÙƒÙŠÙ", Ø±"Ø£ÙŠÙ†", Ø±"Ù…ØªÙ‰", Ø±"Ù„Ù…Ø§Ø°Ø§"]
        }
        
        emotional_state = "neutral"
        confidence = 0.0
        
        for state, indicators in emotional_indicators.items():
            for indicator in indicators:
                if re.search(indicator, user_message.lower()):
                    emotional_state = state
                    confidence = 0.7
                    break
        
        if emotional_state != "neutral":
            return {
                "emotional_state": emotional_state,
                "confidence": confidence,
                "timestamp": time.time()
            }
        
        return {}

    def add_context_item(self, context_type: ContextType, content: Dict[str, Any], 
                        priority: PriorityLevel = PriorityLevel.MEDIUM,
                        ttl: Optional[int] = None) -> str:
        """Ø¥Ø¶Ø§ÙØ© Ø¹Ù†ØµØ± Ø³ÙŠØ§Ù‚ Ø¬Ø¯ÙŠØ¯"""
        context_id = f"{context_type.value}_{int(time.time() * 1000)}"
        
        expires_at = None
        if ttl is not None:
            expires_at = time.time() + ttl
        
        context_item = ContextItem(
            id=context_id,
            type=context_type,
            content=content,
            priority=priority,
            created_at=time.time(),
            expires_at=expires_at,
            source="context_manager"
        )
        
        self.context_store[context_id] = context_item
        self._cleanup_expired_context()
        
        logger.debug(f"â• ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø¹Ù†ØµØ± Ø³ÙŠØ§Ù‚: {context_type.value} (Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: {priority.value})")
        return context_id

    def get_relevant_context(self, query: str, limit: int = 10) -> List[ContextItem]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø°ÙŠ Ø§Ù„ØµÙ„Ø© Ø¨Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"""
        self._cleanup_expired_context()
        
        relevant_items = []
        
        for item in self.context_store.values():
            relevance_score = self._calculate_relevance(item, query)
            if relevance_score > 0.1:  # Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„ØµÙ„Ø©
                relevant_items.append((item, relevance_score))
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ØµÙ„Ø© ÙˆØ§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
        relevant_items.sort(key=lambda x: (x[1], x[0].priority.value), reverse=True)
        
        return [item for item, score in relevant_items[:limit]]

    def _calculate_relevance(self, context_item: ContextItem, query: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© ØµÙ„Ø© Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¨Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"""
        relevance_score = 0.0
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø³ÙŠØ§Ù‚
        content_text = str(context_item.content).lower()
        query_lower = query.lower()
        
        # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        query_words = set(query_lower.split())
        content_words = set(content_text.split())
        
        common_words = query_words.intersection(content_words)
        if common_words:
            relevance_score += len(common_words) * 0.2
        
        # ØªØ¹Ø²ÙŠØ² Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø³ÙŠØ§Ù‚
        type_boost = {
            ContextType.CONVERSATION: 0.3,
            ContextType.USER_PREFERENCE: 0.4,
            ContextType.DOMAIN_KNOWLEDGE: 0.5,
            ContextType.TEMPORAL: 0.1,
            ContextType.TECHNICAL: 0.6
        }
        
        relevance_score += type_boost.get(context_item.type, 0.0)
        
        # ØªØ¹Ø²ÙŠØ² Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
        priority_boost = {
            PriorityLevel.CRITICAL: 0.5,
            PriorityLevel.HIGH: 0.3,
            PriorityLevel.MEDIUM: 0.1,
            PriorityLevel.LOW: 0.0
        }
        
        relevance_score += priority_boost.get(context_item.priority, 0.0)
        
        return min(relevance_score, 1.0)

    def get_conversation_context(self, lookback_turns: int = 5) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø­Ø¯ÙŠØ«"""
        recent_turns = self.conversation_history[-lookback_turns:] if self.conversation_history else []
        
        return {
            "recent_conversation": recent_turns,
            "total_turns": len(self.conversation_history),
            "current_topic": self._extract_current_topic(recent_turns),
            "conversation_flow": self._analyze_conversation_flow(recent_turns)
        }

    def _extract_current_topic(self, recent_turns: List[Dict]) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        if not recent_turns:
            return "Ø¹Ø§Ù…"
        
        # ØªØ­Ù„ÙŠÙ„ Ø¢Ø®Ø± 3 Ø£Ø¯ÙˆØ§Ø± Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹
        recent_text = " ".join([turn["user"] for turn in recent_turns[-3:]])
        
        topic_indicators = {
            "Ø¨Ø±Ù…Ø¬Ø©": [r"ÙƒÙˆØ¯", r"Ø¨Ø±Ù…Ø¬Ø©", r"Ø¨Ø§ÙŠØ«ÙˆÙ†", r"Ø¬Ø§ÙØ§", r"html"],
            "ØªÙ‚Ù†ÙŠØ©": [r"ØªÙ‚Ù†ÙŠØ©", r"ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§", r"Ø°ÙƒØ§Ø¡", r"Ø¢Ù„Ø©"],
            "ØªØ¹Ù„Ù…": [r"ØªØ¹Ù„Ù…", r"Ø¯Ø±Ø§Ø³Ø©", Ø±"Ø´Ø±Ø­", Ø±"ÙÙ‡Ù…"],
            "Ø¨Ø­Ø«": [r"Ø¨Ø­Ø«", Ø±"Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", Ø±"Ù…Ø§ Ù‡Ùˆ", Ø±"Ø´Ø±Ø­"],
            "Ù…Ø´Ø±ÙˆØ¹": [r"Ù…Ø´Ø±ÙˆØ¹", Ø±"ØªØ·Ø¨ÙŠÙ‚", Ø±"Ù…ÙˆÙ‚Ø¹", Ø±"Ø¨Ø±Ù†Ø§Ù…Ø¬"]
        }
        
        for topic, patterns in topic_indicators.items():
            for pattern in patterns:
                if re.search(pattern, recent_text.lower()):
                    return topic
        
        return "Ø¹Ø§Ù…"

    def _analyze_conversation_flow(self, recent_turns: List[Dict]) -> str:
        """ØªØ­Ù„ÙŠÙ„ ØªØ¯ÙÙ‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        if len(recent_turns) < 2:
            return "Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"
        
        last_user_turn = recent_turns[-1]["user"].lower() if recent_turns else ""
        
        if any(word in last_user_turn for word in ["Ø´ÙƒØ±", "Ù…Ù…ØªØ§Ø²", "Ø±Ø§Ø¦Ø¹"]):
            return "Ù†Ù‡Ø§ÙŠØ© Ù…Ø­ØªÙ…Ù„Ø©"
        elif any(word in last_user_turn for word in ["Ù„Ù…Ø§Ø°Ø§", "ÙƒÙŠÙ", "Ø´Ø±Ø­"]):
            return "Ø§Ø³ØªÙØ³Ø§Ø± Ù…ØªØ¹Ù…Ù‚"
        elif any(word in last_user_turn for word in ["Ù…Ø«Ø§Ù„", "Ø¹Ù…Ù„ÙŠ", "ØªØ·Ø¨ÙŠÙ‚"]):
            return "Ø·Ù„Ø¨ Ø£Ù…Ø«Ù„Ø©"
        else:
            return "Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"

    def update_user_preference(self, key: str, value: Any, priority: PriorityLevel = PriorityLevel.MEDIUM):
        """ØªØ­Ø¯ÙŠØ« ØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        self.user_profile[key] = value
        
        # Ø­ÙØ¸ ÙƒØ³ÙŠØ§Ù‚ Ø£ÙŠØ¶Ø§Ù‹
        self.add_context_item(
            ContextType.USER_PREFERENCE,
            {"preference_key": key, "preference_value": value},
            priority,
            ttl=86400  # Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¨Ø¹Ø¯ ÙŠÙˆÙ…
        )
        
        logger.debug(f"ğŸ¯ ØªÙ… ØªØ­Ø¯ÙŠØ« ØªÙØ¶ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {key} = {value}")

    def update_domain_context(self, domain: str, context_data: Dict[str, Any]):
        """ØªØ­Ø¯ÙŠØ« Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø¬Ø§Ù„"""
        self.domain_context[domain] = {
            **self.domain_context.get(domain, {}),
            **context_data,
            "last_updated": time.time()
        }
        
        self.add_context_item(
            ContextType.DOMAIN_KNOWLEDGE,
            {"domain": domain, **context_data},
            PriorityLevel.HIGH,
            ttl=7200  # Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¨Ø¹Ø¯ Ø³Ø§Ø¹ØªÙŠÙ†
        )

    def get_comprehensive_context(self, query: str) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚ Ø´Ø§Ù…Ù„ Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"""
        
        relevant_context_items = self.get_relevant_context(query)
        conversation_context = self.get_conversation_context()
        
        comprehensive_context = {
            "query": query,
            "timestamp": time.time(),
            "session_id": self.session_id,
            
            # Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ®Ø§Ø·Ø¨ÙŠ
            "conversation": conversation_context,
            
            # Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ
            "user_profile": self.user_profile,
            
            # Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø¬Ø§Ù„
            "domain_context": self._get_relevant_domains(query),
            
            # Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
            "context_items": [item.to_dict() for item in relevant_context_items],
            
            # Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠØ©
            "suggestions": self._generate_context_suggestions(query, relevant_context_items),
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙˆØ§ÙŠØ§
            "intent_analysis": self._analyze_intent_with_context(query, relevant_context_items)
        }
        
        return comprehensive_context

    def _get_relevant_domains(self, query: str) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© Ø¨Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"""
        relevant_domains = {}
        detected_domains = self._detect_domains(query)
        
        for domain in detected_domains:
            if domain in self.domain_context:
                relevant_domains[domain] = self.domain_context[domain]
        
        return relevant_domains

    def _generate_context_suggestions(self, query: str, context_items: List[ContextItem]) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚"""
        suggestions = []
        
        # Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        if len(self.conversation_history) > 3:
            recent_topics = set()
            for turn in self.conversation_history[-4:]:
                topic = self._extract_current_topic([turn])
                if topic != "Ø¹Ø§Ù…":
                    recent_topics.add(topic)
            
            if len(recent_topics) == 1:
                suggestions.append(f"ÙŠØ¨Ø¯Ùˆ Ø£Ù†Ùƒ Ù…Ù‡ØªÙ… Ø¨Ù…ÙˆØ¶ÙˆØ¹ {list(recent_topics)[0]}")
        
        # Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ¶ÙŠÙ„Ø§Øª
        if "preferred_detail_level" in self.user_profile:
            detail_pref = self.user_profile["preferred_detail_level"]
            if detail_pref == "high_detail":
                suggestions.append("Ø³Ø£Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙØµÙ„Ø© ÙƒÙ…Ø§ ØªÙØ¶Ù„")
            elif detail_pref == "low_detail":
                suggestions.append("Ø³Ø£Ø®ØªØµØ± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙƒÙ…Ø§ ØªÙØ¶Ù„")
        
        return suggestions

    def _analyze_intent_with_context(self, query: str, context_items: List[ContextItem]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙˆØ§ÙŠØ§ Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„Ø³ÙŠØ§Ù‚"""
        intent_analysis = {
            "primary_intent": "information_request",
            "confidence": 0.7,
            "contextual_factors": [],
            "expected_response_type": "detailed_explanation"
        }
        
        # ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚
        for item in context_items:
            if item.type == ContextType.CONVERSATION:
                intent_analysis["contextual_factors"].append("Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©")
            
            elif item.type == ContextType.USER_PREFERENCE:
                if "preferred_help_type" in item.content:
                    intent_analysis["expected_response_type"] = item.content["preferred_help_type"]
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ
        query_lower = query.lower()
        
        if any(word in query_lower for word in ["ÙƒÙˆØ¯", "Ø¨Ø±Ù…Ø¬Ø©", "Ø§ÙƒØªØ¨", "Ø§Ù†Ø´Ø¦"]):
            intent_analysis["primary_intent"] = "code_generation"
            intent_analysis["confidence"] = 0.9
        
        elif any(word in query_lower for word in ["Ø´Ø±Ø­", "Ù…Ø§ Ù‡Ùˆ", "Ù…ÙÙ‡ÙˆÙ…"]):
            intent_analysis["primary_intent"] = "explanation"
            intent_analysis["confidence"] = 0.8
        
        elif any(word in query_lower for word in ["ÙƒÙŠÙ", "Ø·Ø±ÙŠÙ‚Ø©", "Ø®Ø·ÙˆØ§Øª"]):
            intent_analysis["primary_intent"] = "procedure"
            intent_analysis["expected_response_type"] = "step_by_step"
        
        return intent_analysis

    def _cleanup_expired_context(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©"""
        current_time = time.time()
        expired_ids = []
        
        for context_id, item in self.context_store.items():
            if item.is_expired():
                expired_ids.append(context_id)
        
        for context_id in expired_ids:
            del self.context_store[context_id]
        
        if expired_ids:
            logger.debug(f"ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ {len(expired_ids)} Ø¹Ù†ØµØ± Ø³ÙŠØ§Ù‚ Ù…Ù†ØªÙ‡ÙŠ")

    def clear_context(self, context_type: Optional[ContextType] = None):
        """Ù…Ø³Ø­ Ø§Ù„Ø³ÙŠØ§Ù‚ (ÙƒÙ„ÙŠ Ø£Ùˆ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹)"""
        if context_type is None:
            # Ù…Ø³Ø­ ÙƒÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚
            self.context_store.clear()
            self.conversation_history.clear()
            self.user_profile.clear()
            self.domain_context.clear()
            logger.info("ğŸ§¹ ØªÙ… Ù…Ø³Ø­ ÙƒÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚")
        else:
            # Ù…Ø³Ø­ Ø³ÙŠØ§Ù‚ Ù†ÙˆØ¹ Ù…Ø­Ø¯Ø¯
            ids_to_remove = [
                context_id for context_id, item in self.context_store.items()
                if item.type == context_type
            ]
            for context_id in ids_to_remove:
                del self.context_store[context_id]
            logger.info(f"ğŸ§¹ ØªÙ… Ù…Ø³Ø­ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù†ÙˆØ¹: {context_type.value}")

    def get_context_stats(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø³ÙŠØ§Ù‚"""
        self._cleanup_expired_context()
        
        type_counts = {}
        priority_counts = {}
        
        for item in self.context_store.values():
            type_counts[item.type.value] = type_counts.get(item.type.value, 0) + 1
            priority_counts[item.priority.value] = priority_counts.get(item.priority.value, 0) + 1
        
        return {
            "total_context_items": len(self.context_store),
            "conversation_turns": len(self.conversation_history),
            "user_preferences": len(self.user_profile),
            "active_domains": len(self.domain_context),
            "context_by_type": type_counts,
            "context_by_priority": priority_counts,
            "session_duration": time.time() - (self.conversation_history[0]["timestamp"] if self.conversation_history else time.time())
        }

    def export_context(self) -> Dict[str, Any]:
        """ØªØµØ¯ÙŠØ± Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠ"""
        return {
            "session_id": self.session_id,
            "exported_at": time.time(),
            "conversation_history": self.conversation_history,
            "user_profile": self.user_profile,
            "domain_context": self.domain_context,
            "context_items": [item.to_dict() for item in self.context_store.values()],
            "stats": self.get_context_stats()
        }

    def import_context(self, context_data: Dict[str, Any]):
        """Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚"""
        try:
            self.session_id = context_data.get("session_id", self.session_id)
            self.conversation_history = context_data.get("conversation_history", [])
            self.user_profile = context_data.get("user_profile", {})
            self.domain_context = context_data.get("domain_context", {})
            
            # Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø³ÙŠØ§Ù‚
            self.context_store.clear()
            for item_data in context_data.get("context_items", []):
                try:
                    context_item = ContextItem(
                        id=item_data["id"],
                        type=ContextType(item_data["type"]),
                        content=item_data["content"],
                        priority=PriorityLevel(item_data["priority"]),
                        created_at=item_data["created_at"],
                        expires_at=item_data.get("expires_at"),
                        source=item_data.get("source", "imported"),
                        confidence=item_data.get("confidence", 1.0),
                        metadata=item_data.get("metadata", {})
                    )
                    self.context_store[item_data["id"]] = context_item
                except Exception as e:
                    logger.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¹Ù†ØµØ± Ø§Ù„Ø³ÙŠØ§Ù‚: {e}")
            
            logger.info(f"ğŸ“¥ ØªÙ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¨Ù†Ø¬Ø§Ø­ ({len(self.context_store)} Ø¹Ù†ØµØ±)")
        
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚: {e}")
            raise

# Ù†Ø³Ø®Ø© Ù…Ø¨Ø³Ø·Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³Ø±ÙŠØ¹
def create_context_manager(session_id: str = "default") -> ContextManager:
    """Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ø³ÙŠØ§Ù‚"""
    return ContextManager(session_id)

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø§Ù„Ù…ÙŠ
_global_context_manager = None

def get_global_context_manager() -> ContextManager:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¯ÙŠØ± Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ"""
    global _global_context_manager
    if _global_context_manager is None:
        _global_context_manager = ContextManager("global")
    return _global_context_manager
