# core/brain.py â€” Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
from __future__ import annotations
from typing import List, Tuple, Dict, Optional
import logging
import re
from datetime import datetime

from core.memory import search_memory, add_fact, save_conv, get_context
from core.web_search import web_search, fetch_text, wiki_summary_ar
from core.code_team import build_project
from core.coder import generate_code
from core.learn_loop import learn_from_conversation

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logger = logging.getLogger(__name__)

class IntentAnalyzer:
    """Ù…Ø­Ù„Ù„ Ù†ÙˆØ§ÙŠØ§ Ù…ØªÙ‚Ø¯Ù…"""
    
    def __init__(self):
        self.code_patterns = [
            r"(Ø§ÙƒØªØ¨|Ø§Ù†Ø´Ø¦|Ø§ØµÙ†Ø¹|Ø¨Ø±Ù…Ø¬)(.*)(ÙƒÙˆØ¯|Ø¨Ø±Ù†Ø§Ù…Ø¬|Ø¯Ø§Ù„Ø©|Ø³ÙƒØ±ÙŠØ¨Øª)",
            r"(ÙƒÙˆØ¯|Ø¨Ø±Ù…Ø¬Ø©|Ø´ÙØ±Ø©)\s+(Ù„|ÙÙŠ)\s+",
            r"(python|javascript|java|html|css|sql)\s+"
        ]
        
        self.project_patterns = [
            r"(Ø§Ø¨Ù†ÙŠ|Ø§Ù†Ø´Ø¦|Ø§ØµÙ†Ø¹)(.*)(Ù…Ø´Ø±ÙˆØ¹|Ù†Ø¸Ø§Ù…|ØªØ·Ø¨ÙŠÙ‚|Ù…ÙˆÙ‚Ø¹)",
            r"(Ù…Ø´Ø±ÙˆØ¹|ØªØ·Ø¨ÙŠÙ‚)\s+(Ù„|ÙÙŠ)\s+",
            r"(ØªØµÙ…ÙŠÙ…|Ø¨Ø±Ù…Ø¬Ø©)\s+(Ù…ÙˆÙ‚Ø¹|ØªØ·Ø¨ÙŠÙ‚)"
        ]
        
        self.question_patterns = [
            r"(Ù…Ø§ Ù‡Ùˆ|Ù…Ø§Ù‡Ùˆ|Ù…Ø§ Ù‡ÙŠ|Ù…Ø§Ù‡ÙŠ|ÙƒÙŠÙ|Ù„Ù…Ø§Ø°Ø§|Ø£ÙŠÙ†|Ù…ØªÙ‰)",
            r"(Ø´Ø±Ø­|ØªØ¹Ø±ÙŠÙ|Ù…ÙÙ‡ÙˆÙ…)\s+",
            r"(Ù…Ø§ Ø±Ø£ÙŠÙƒ|Ù…Ø§ ØªÙ‚ÙˆÙ„)\s+ÙÙŠ"
        ]

    def analyze(self, text: str) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙˆØ§ÙŠØ§ Ù…Ø¹ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø«Ù‚Ø©"""
        text = self._normalize_text(text)
        
        intents = []
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙˆØ§ÙŠØ§
        if self._matches_patterns(text, self.code_patterns):
            intents.append({"type": "code", "confidence": 0.85})
        
        if self._matches_patterns(text, self.project_patterns):
            intents.append({"type": "project", "confidence": 0.80})
            
        if self._matches_patterns(text, self.question_patterns):
            intents.append({"type": "question", "confidence": 0.75})
        
        # Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ù†ÙˆØ§ÙŠØ§ ÙˆØ§Ø¶Ø­Ø©
        if not intents:
            if len(text.split()) <= 4:
                intents.append({"type": "small_talk", "confidence": 0.90})
            else:
                intents.append({"type": "general_search", "confidence": 0.70})
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø«Ù‚Ø©
        intents.sort(key=lambda x: x["confidence"], reverse=True)
        return intents[0] if intents else {"type": "unknown", "confidence": 0.5}

    def _normalize_text(self, text: str) -> str:
        """ØªÙ†Ù‚ÙŠØ© Ø§Ù„Ù†Øµ Ù„Ù„ØªØ­Ù„ÙŠÙ„"""
        text = re.sub(r'[^\w\s]', ' ', text.lower())
        return ' '.join(text.split())

    def _matches_patterns(self, text: str, patterns: List[str]) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
        for pattern in patterns:
            if re.search(pattern, text):
                return True
        return False

class ResponseGenerator:
    """Ù…ÙˆÙ„Ø¯ Ø±Ø¯ÙˆØ¯ Ø°ÙƒÙŠ"""
    
    def __init__(self):
        self.openers = {
            "code": "ğŸ”§ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙŠ Ø·Ù„Ø¨ØªÙ‡:",
            "project": "ğŸš€ Ø¨Ø¯Ø£Øª Ø¨Ù†Ø§Ø¡ Ù…Ø´Ø±ÙˆØ¹Ùƒ:",
            "question": "ğŸ“š Ø¥Ù„ÙŠÙƒ Ù…Ø§ ÙˆØ¬Ø¯ØªÙ‡:",
            "general_search": "ğŸ” Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:",
            "small_talk": "ğŸ‘‹ "
        }
        
        self.fallbacks = {
            "code": "Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ù…Ù†Ø§Ø³Ø¨. ÙŠÙ…ÙƒÙ†Ùƒ ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø£ÙƒØ«Ø±ØŸ",
            "project": "Ø£Ø­ØªØ§Ø¬ Ù…Ø²ÙŠØ¯Ø§Ù‹ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø¹Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨.",
            "question": "Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©. Ø¬Ø±Ø¨ ØµÙŠØ§ØºØ© Ø£Ø®Ø±Ù‰ Ø£Ùˆ Ø§Ø³Ø£Ù„ Ø¹Ù† Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø®ØªÙ„Ù.",
            "general_search": "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØµÙŠØ§ØºØ©ØŸ"
        }

    def generate_opener(self, intent_type: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù‚Ø¯Ù…Ø© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù†ÙˆØ§ÙŠØ§"""
        return self.openers.get(intent_type, "ğŸ’¡ ")

    def generate_fallback(self, intent_type: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ø¨Ø¯ÙŠÙ„ Ø¹Ù†Ø¯Ù…Ø§ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬"""
        return self.fallbacks.get(intent_type, "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")

class ConversationManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    
    def __init__(self):
        self.context_history = []
        self.max_context_length = 5

    def add_context(self, user_msg: str, bot_msg: str):
        """Ø¥Ø¶Ø§ÙØ© Ø³ÙŠØ§Ù‚ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        context = {
            "user": user_msg,
            "bot": bot_msg,
            "timestamp": datetime.now().isoformat()
        }
        self.context_history.append(context)
        
        # Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ù…Ø¹Ù‚ÙˆÙ„ Ù„Ù„Ø³ÙŠØ§Ù‚
        if len(self.context_history) > self.max_context_length:
            self.context_history.pop(0)

    def get_recent_context(self) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø­Ø¯ÙŠØ«"""
        return self.context_history[-2:] if len(self.context_history) >= 2 else []

# Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©
intent_analyzer = IntentAnalyzer()
response_generator = ResponseGenerator()
conversation_manager = ConversationManager()

def enhanced_chat_answer(q: str) -> Tuple[str, List[dict]]:
    """
    Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ù† chat_answer Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ§ÙŠØ§ Ù…ØªÙ‚Ø¯Ù…
    """
    q = (q or "").strip()
    if not q:
        return "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø³Ø¤Ø§Ù„ Ø£Ùˆ Ø·Ù„Ø¨.", []

    logger.info(f"Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„Ø©: {q}")

    try:
        # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙˆØ§ÙŠØ§
        intent = intent_analyzer.analyze(q)
        logger.info(f"ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙˆØ§ÙŠØ§: {intent}")

        # 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ§ÙŠØ§
        if intent["type"] == "code" and intent["confidence"] > 0.7:
            return handle_code_request(q, intent)
            
        elif intent["type"] == "project" and intent["confidence"] > 0.7:
            return handle_project_request(q, intent)
            
        elif intent["type"] == "question":
            return handle_question_request(q, intent)
            
        else:
            return handle_general_request(q, intent)

    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
        return "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.", []

def handle_code_request(q: str, intent: Dict) -> Tuple[str, List[dict]]:
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø£ÙƒÙˆØ§Ø¯"""
    try:
        result = generate_code(q)
        
        if result and result.get("code"):
            code = result["code"]
            lang = result.get("lang", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
            title = result.get("title", "ÙƒÙˆØ¯ Ù…Ø·Ù„ÙˆØ¨")
            
            # ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯
            if is_valid_code(code, lang):
                response = f"{response_generator.generate_opener('code')}\n\n"
                response += f"**{title}** ({lang})\n\n"
                response += f"```{lang}\n{code}\n```"
                
                # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                add_fact(f"ÙƒÙˆØ¯ {lang}: {title}", source="code_generation")
                save_conv(q, response)
                
                return response, []
            else:
                return "Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙÙˆÙ„Ø¯ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§ØªØŸ", []
        else:
            return response_generator.generate_fallback("code"), []

    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯: {e}")
        return "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.", []

def handle_project_request(q: str, intent: Dict) -> Tuple[str, List[dict]]:
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹"""
    try:
        result = build_project(q)
        
        if result.get("ok"):
            files = result.get("files", {})
            issues = result.get("issues", [])
            tips = result.get("tips", "")
            
            response = f"{response_generator.generate_opener('project')}\n\n"
            response += f"ğŸ“ **Ø§Ù„Ù…Ù„ÙØ§Øª:** {', '.join(files.keys())}\n"
            response += f"âš ï¸ **Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª:** {len(issues)}\n"
            response += f"ğŸ’¡ **Ù†ØµÙŠØ­Ø©:** {tips}\n\n"
            
            # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ Ù…Ù„Ù ÙƒÙ…Ø«Ø§Ù„
            if files:
                first_file = list(files.keys())[0]
                file_content = files[first_file][:500] + "..." if len(files[first_file]) > 500 else files[first_file]
                response += f"**Ù…Ø«Ø§Ù„ Ù…Ù† {first_file}:**\n```\n{file_content}\n```"
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            for filename in list(files.keys())[:3]:
                add_fact(f"Ù…Ù„Ù Ù…Ø´Ø±ÙˆØ¹: {filename}", source="project_builder")
            
            save_conv(q, response)
            return response, []
        else:
            return response_generator.generate_fallback("project"), []

    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹: {e}")
        return "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.", []

def handle_question_request(q: str, intent: Dict) -> Tuple[str, List[dict]]:
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª"""
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø£ÙˆÙ„Ø§Ù‹
    mem_results = search_memory(q, limit=8)
    mem_texts = [r["text"] for r in mem_results if r["score"] > 0.2]
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙƒØ§ÙÙŠØ©
    if mem_texts and any(r["score"] > 1.0 for r in mem_results):
        response = f"{response_generator.generate_opener('question')}\n"
        response += "\n".join([f"â€¢ {text}" for text in mem_texts[:3]])
        save_conv(q, response)
        return response, []

    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ÙˆÙŠØ¨ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
    try:
        web_results = web_search(q, max_results=5)
        sources = []
        
        if web_results:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙÙŠØ¯Ø©
            useful_info = extract_useful_info(web_results[:3])
            if useful_info:
                response = f"{response_generator.generate_opener('question')}\n"
                response += "\n".join([f"â€¢ {info}" for info in useful_info[:4]])
                sources = [{"title": r.get("title", ""), "url": r.get("url", "")} for r in web_results[:3]]
                
                # Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
                for info in useful_info[:2]:
                    if should_learn_info(info):
                        add_fact(info, source="web_learning")
                
                save_conv(q, response)
                return response, sources

    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")

    return response_generator.generate_fallback("question"), []

def handle_general_request(q: str, intent: Dict) -> Tuple[str, List[dict]]:
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©"""
    # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø± ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„ÙˆÙŠØ¨
    mem_results = search_memory(q, limit=5)
    mem_texts = [r["text"] for r in mem_results if r["score"] > 0.1]
    
    try:
        web_results = web_search(q, max_results=4)
        useful_info = extract_useful_info(web_results[:2]) if web_results else []
        
        all_info = mem_texts + useful_info
        
        if all_info:
            response = f"{response_generator.generate_opener('general_search')}\n"
            response += "\n".join([f"â€¢ {info}" for info in all_info[:5]])
            sources = [{"title": r.get("title", ""), "url": r.get("url", "")} for r in web_results[:3]] if web_results else []
            
            save_conv(q, response)
            return response, sources
        else:
            return response_generator.generate_fallback("general_search"), []

    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ø§Ù…Ø©: {e}")
        return "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª. Ø¬Ø±Ø¨ ØµÙŠØ§ØºØ© Ø£Ø®Ø±Ù‰.", []

def is_valid_code(code: str, lang: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯"""
    if not code or len(code.strip()) < 10:
        return False
        
    if lang == "html" and not any(tag in code for tag in ["<html", "<body", "<div"]):
        return False
        
    if lang == "python" and not any(char in code for char in [":", "def ", "import "]):
        return False
        
    return True

def extract_useful_info(web_results: List[Dict]) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙÙŠØ¯Ø© Ù…Ù† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙˆÙŠØ¨"""
    useful_info = []
    
    for result in web_results:
        snippet = result.get("snippet", "") or result.get("body", "")
        if snippet and len(snippet) > 50:
            # ØªÙ‚Ø³ÙŠÙ… Ø¥Ù„Ù‰ Ø¬Ù…Ù„ Ù…ÙÙŠØ¯Ø©
            sentences = [s.strip() for s in snippet.split(".") if 20 < len(s.strip()) < 200]
            useful_info.extend(sentences[:2])
    
    return useful_info[:6]  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ 6 Ø¬Ù…Ù„

def should_learn_info(info: str) -> bool:
    """ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªØ³ØªØ­Ù‚ Ø§Ù„ØªØ¹Ù„Ù…"""
    if len(info) < 30:
        return False
        
    excluded_phrases = ["Ø§Ù†Ù‚Ø± Ù‡Ù†Ø§", "Ù„Ù„Ù…Ø²ÙŠØ¯", "Ø§Ø´ØªØ±Ùƒ Ø§Ù„Ø¢Ù†", "Ø¥Ø¹Ù„Ø§Ù†"]
    if any(phrase in info for phrase in excluded_phrases):
        return False
        
    return True

# Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚
def chat_answer(q: str) -> Tuple[str, List[dict]]:
    """ÙˆØ§Ø¬Ù‡Ø© Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚"""
    return enhanced_chat_answer(q)
