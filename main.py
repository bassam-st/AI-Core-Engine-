#!/usr/bin/env python3
# Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© - Ø¨Ù†Ù…Ø§Ø°Ø¬ Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø±

import os
import json
import logging
import requests
from datetime import datetime
from flask import Flask, request, jsonify, render_template
import numpy as np
import nltk
from sentence_transformers import SentenceTransformer, util

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø±
try:
    # Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ÙÙ‡Ù… Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ (Ø£Ø®Ù ÙˆØ£Ø³Ø±Ø¹)
    semantic_model = SentenceTransformer('all-MiniLM-L6-v2')
    MODEL_LOADED = True
except:
    MODEL_LOADED = False

app = Flask(__name__)

class AdvancedAICore:
    def __init__(self):
        self.setup_directories()
        self.load_knowledge()
        self.setup_nltk()
        self.conversation_history = []
        
    def setup_directories(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©"""
        os.makedirs('knowledge', exist_ok=True)
        os.makedirs('memory', exist_ok=True)
        os.makedirs('models', exist_ok=True)
    
    def setup_nltk(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ NLTK"""
        try:
            nltk.data.find('tokenizers/punkt')
        except LookupError:
            nltk.download('punkt')
    
    def load_knowledge(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ÙˆØ³Ø¹Ø©"""
        try:
            with open('knowledge/advanced_knowledge.json', 'r', encoding='utf-8') as f:
                self.knowledge = json.load(f)
        except:
            self.knowledge = {
                "qa_pairs": {
                    "Ø¨Ø±Ù…Ø¬Ø©": {
                        "Ù…Ø§ Ù‡Ùˆ Ø¨Ø§ÙŠØ«ÙˆÙ†ØŸ": "Ø¨Ø§ÙŠØ«ÙˆÙ† Ù„ØºØ© Ø¨Ø±Ù…Ø¬Ø© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø³Ù‡Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù…ØŒ ØªØ³ØªØ®Ø¯Ù… ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„ÙˆÙŠØ¨ØŒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ ÙˆØ§Ù„Ø£ØªÙ…ØªØ©.",
                        "ÙƒÙŠÙ Ø£Ù†Ø´Ø¦ Ù…ÙˆÙ‚Ø¹ ÙˆÙŠØ¨ØŸ": "Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆÙ‚Ø¹ ÙˆÙŠØ¨: 1) ØªØ¹Ù„Ù… HTML/CSS/JavaScript 2) Ø§Ø®ØªØ± Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ù…Ø«Ù„ Flask Ø£Ùˆ Django 3) Ø§Ø³ØªØ®Ø¯Ù… Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª 4) Ø§Ù†Ø´Ø± Ø¹Ù„Ù‰ Ø®Ø§Ø¯Ù… ÙˆÙŠØ¨",
                        "Ù…Ø§ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† list Ùˆ tupleØŸ": "List Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„ØŒ Tuple Ø«Ø§Ø¨ØªØ© Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§. List ØªØ³ØªØ®Ø¯Ù… [] Ùˆ Tuple ØªØ³ØªØ®Ø¯Ù… ()"
                    },
                    "Ø´Ø¨ÙƒØ§Øª": {
                        "Ù…Ø§ Ù‡Ùˆ IPØŸ": "Ø¹Ù†ÙˆØ§Ù† IP Ù‡Ùˆ Ø¹Ù†ÙˆØ§Ù† ÙØ±ÙŠØ¯ ÙŠØ­Ø¯Ø¯ Ø¬Ù‡Ø§Ø²Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø¨ÙƒØ©ØŒ Ù…Ø«Ù„ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù†Ø²Ù„ ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ.",
                        "ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ DNSØŸ": "DNS ÙŠØ­ÙˆÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª (Ù…Ø«Ù„ google.com) Ø¥Ù„Ù‰ Ø¹Ù†Ø§ÙˆÙŠÙ† IP Ø±Ù‚Ù…ÙŠØ© ÙŠÙ…ÙƒÙ† Ù„Ù„Ø£Ø¬Ù‡Ø²Ø© ÙÙ‡Ù…Ù‡Ø§.",
                        "Ù…Ø§ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† TCP Ùˆ UDPØŸ": "TCP Ù…ÙˆØ«ÙˆÙ‚ Ù…Ø¹ ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…ØŒ UDP Ø³Ø±ÙŠØ¹ Ø¨Ø¯ÙˆÙ† ØªØ£ÙƒÙŠØ¯ - Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØ§Ù„ÙÙŠØ¯ÙŠÙˆ"
                    },
                    "Ø£Ù†Ø¸Ù…Ø©": {
                        "Ù…Ø§ Ù‡Ùˆ LinuxØŸ": "Linux Ù†Ø¸Ø§Ù… ØªØ´ØºÙŠÙ„ Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø±ØŒ Ù…Ø³ØªÙ‚Ø± ÙˆØ¢Ù…Ù†ØŒ ÙŠØ³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„Ø®ÙˆØ§Ø¯Ù… ÙˆØ§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©.",
                        "ÙƒÙŠÙ Ø£Ø±Ø§Ù‚Ø¨ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…ØŸ": "Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø¯ÙˆØ§Øª Ù…Ø«Ù„: top, htop, ps, vmstat Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ù‚Ø±Øµ.",
                        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø­Ø§ÙˆÙŠØ©ØŸ": "Ø§Ù„Ø­Ø§ÙˆÙŠØ© (Container) Ø­Ø²Ù…Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªØ·Ø¨ÙŠÙ‚ ÙˆÙƒÙ„ Ø§Ø¹ØªÙ…Ø§Ø¯Ø§ØªÙ‡ØŒ ØªØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ø¹Ø²ÙˆÙ„ Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¶ÙŠÙ."
                    }
                },
                "code_templates": {
                    "python_web": """from flask import Flask, render_template, request
import sqlite3

app = Flask(__name__)

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/api/data')
def get_data():
    return {'message': 'Ù…Ø±Ø­Ø¨Ø§Ù‹ Ù…Ù† API!'}

if __name__ == '__main__':
    app.run(debug=True)""",
                    
                    "python_data_analysis": """import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
data = pd.read_csv('data.csv')

# ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø§Ø³ÙŠ
print("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
print(data.info())
print("\\nØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:")
print(data.describe())

# ØªØµÙˆØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
plt.figure(figsize=(10, 6))
data.plot()
plt.title('ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª')
plt.show()""",
                    
                    "html_responsive": """<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ù…ÙˆÙ‚Ø¹ÙŠ Ø§Ù„Ù…ØªØ¬Ø§ÙˆØ¨</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: Arial, sans-serif; line-height: 1.6; }
        .container { max-width: 1200px; margin: 0 auto; padding: 20px; }
        .header { background: #2c3e50; color: white; padding: 1rem; text-align: center; }
        @media (max-width: 768px) {
            .container { padding: 10px; }
        }
    </style>
</head>
<body>
    <header class="header">
        <h1>Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù…ÙˆÙ‚Ø¹ÙŠ</h1>
    </header>
    <div class="container">
        <p>Ù‡Ø°Ø§ Ù…ÙˆÙ‚Ø¹ Ù…ØªØ¬Ø§ÙˆØ¨ ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©</p>
    </div>
</body>
</html>"""
                },
                "user_profiles": {},
                "learning_data": {}
            }
            self.save_knowledge()
    
    def save_knowledge(self):
        """Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
        try:
            with open('knowledge/advanced_knowledge.json', 'w', encoding='utf-8') as f:
                json.dump(self.knowledge, f, ensure_ascii=False, indent=2)
        except:
            pass
    
    def semantic_similarity(self, text1, text2):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ø¨ÙŠÙ† Ù†ØµÙŠÙ†"""
        if not MODEL_LOADED:
            # Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø¯ÙŠÙ„Ø© Ø¨Ø³ÙŠØ·Ø©
            words1 = set(text1.lower().split())
            words2 = set(text2.lower().split())
            common = words1.intersection(words2)
            return len(common) / max(len(words1), len(words2))
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø­Ù…Ù„
        emb1 = semantic_model.encode(text1, convert_to_tensor=True)
        emb2 = semantic_model.encode(text2, convert_to_tensor=True)
        similarity = util.pytorch_cos_sim(emb1, emb2)
        return similarity.item()
    
    def find_best_answer(self, question, category=None):
        """Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙØ¶Ù„ Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ"""
        best_score = 0
        best_answer = None
        
        if category and category in self.knowledge["qa_pairs"]:
            categories = [category]
        else:
            categories = self.knowledge["qa_pairs"].keys()
        
        for cat in categories:
            for q, a in self.knowledge["qa_pairs"][cat].items():
                score = self.semantic_similarity(question, q)
                if score > best_score:
                    best_score = score
                    best_answer = a
        
        return best_answer if best_score > 0.3 else None
    
    def analyze_intent(self, message):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ù…ØªÙ‚Ø¯Ù…Ø©"""
        message_lower = message.lower()
        
        intents = {
            "code_generation": ["Ø£Ù†Ø´Ø¦", "Ø§ØµÙ†Ø¹", "Ø§ÙƒØªØ¨", "Ø¨Ø±Ù…Ø¬Ø©", "ÙƒÙˆØ¯", "Ø³ÙƒØ±ÙŠØ¨Øª"],
            "explanation": ["Ù…Ø§ Ù‡Ùˆ", "Ù…Ø§ Ù‡ÙŠ", "Ø§Ø´Ø±Ø­", "ÙƒÙŠÙ", "Ù„Ù…Ø§Ø°Ø§"],
            "problem_solving": ["Ù…Ø´ÙƒÙ„Ø©", "Ø®Ø·Ø£", "Ù„Ø§ ÙŠØ¹Ù…Ù„", "Ø­Ù„", "Ø¥ØµÙ„Ø§Ø­"],
            "analysis": ["Ø­Ù„Ù„", "Ø­Ù„Ù„ÙŠ", "Ø±Ø£ÙŠÙƒ", "ØªØ­Ù„ÙŠÙ„"],
            "learning": ["ØªØ¹Ù„Ù…", "ØªØ¹Ù„ÙŠÙ…", "Ø¯ÙˆØ±Ø©", "ÙƒÙˆØ±Ø³"]
        }
        
        for intent, keywords in intents.items():
            for keyword in keywords:
                if keyword in message_lower:
                    return intent
        
        return "general"
    
    def generate_ai_response(self, message):
        """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ø°ÙƒÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­Ù„ÙŠØ©"""
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ø£ÙˆÙ„Ø§Ù‹
        answer = self.find_best_answer(message)
        if answer:
            return answer
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙŠØ©
        intent = self.analyze_intent(message)
        
        if intent == "code_generation":
            return self.generate_smart_code(message)
        elif intent == "explanation":
            return self.generate_explanation(message)
        else:
            return self.generate_contextual_response(message)
    
    def generate_smart_code(self, message):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø°ÙƒÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø·Ù„Ø¨"""
        message_lower = message.lower()
        
        if any(word in message_lower for word in ["Ù…ÙˆÙ‚Ø¹", "ÙˆÙŠØ¨", "web"]):
            return f"ğŸŒ ÙƒÙˆØ¯ Ù…ÙˆÙ‚Ø¹ ÙˆÙŠØ¨ Ù…ØªØ¬Ø§ÙˆØ¨:\n\n```html\n{self.knowledge['code_templates']['html_responsive']}\n```"
        
        elif any(word in message_lower for word in ["Ø¨ÙŠØ§Ù†Ø§Øª", "ØªØ­Ù„ÙŠÙ„", "data"]):
            return f"ğŸ“Š ÙƒÙˆØ¯ ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª:\n\n```python\n{self.knowledge['code_templates']['python_data_analysis']}\n```"
        
        elif any(word in message_lower for word in ["Ø¨ÙˆØª", "Ø¯Ø±Ø¯Ø´Ø©", "chat"]):
            bot_code = """import requests

class ChatBot:
    def __init__(self):
        self.responses = {
            'Ù…Ø±Ø­Ø¨Ø§Ù‹': 'Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ',
            'ÙƒÙŠÙ Ø§Ù„Ø­Ø§Ù„': 'Ø£Ù†Ø§ Ø¨Ø®ÙŠØ±ØŒ Ø´ÙƒØ±Ø§Ù‹ Ù„Ø³Ø¤Ø§Ù„Ùƒ!'
        }
    
    def respond(self, message):
        return self.responses.get(message, 'Ù„Ù… Ø£ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ')

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙˆØª
bot = ChatBot()
print(bot.respond('Ù…Ø±Ø­Ø¨Ø§Ù‹'))"""
            return f"ğŸ¤– ÙƒÙˆØ¯ Ø¨ÙˆØª Ø¯Ø±Ø¯Ø´Ø©:\n\n```python\n{bot_code}\n```"
        
        else:
            return f"ğŸ’» ÙƒÙˆØ¯ Python Ø£Ø³Ø§Ø³ÙŠ:\n\n```python\n{self.knowledge['code_templates']['python_web']}\n```"
    
    def generate_explanation(self, message):
        """ØªÙˆÙ„ÙŠØ¯ Ø´Ø±Ø­ Ø°ÙƒÙŠ"""
        concepts = {
            "python": "Ù„ØºØ© Ø¨Ø±Ù…Ø¬Ø© Ø³Ù‡Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù… ÙˆÙ‚ÙˆÙŠØ©ØŒ ØªØ³ØªØ®Ø¯Ù… ÙÙŠ Ù…Ø¬Ø§Ù„Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©",
            "html": "Ù„ØºØ© ØªØ±Ù…ÙŠØ² Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ ØµÙØ­Ø§Øª Ø§Ù„ÙˆÙŠØ¨",
            "css": "Ù„ØºØ© ØªÙ†Ø³ÙŠÙ‚ Ù„ØªØ¬Ù…ÙŠÙ„ ØµÙØ­Ø§Øª Ø§Ù„ÙˆÙŠØ¨",
            "javascript": "Ù„ØºØ© Ø¨Ø±Ù…Ø¬Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ ØµÙØ­Ø§Øª ÙˆÙŠØ¨ ØªÙØ§Ø¹Ù„ÙŠØ©",
            "Ø´Ø¨ÙƒØ©": "Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø¬Ù‡Ø²Ø© Ù…ØªØµÙ„Ø© Ù…Ø¹Ø§Ù‹ Ù„ØªØ¨Ø§Ø¯Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
            "Ø®Ø§Ø¯Ù…": "Ø¬Ù‡Ø§Ø² Ù‚ÙˆÙŠ ÙŠÙ‚Ø¯Ù… Ø®Ø¯Ù…Ø§Øª Ù„Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø£Ø®Ø±Ù‰"
        }
        
        for concept, explanation in concepts.items():
            if concept in message.lower():
                return f"ğŸ“š Ø´Ø±Ø­ {concept}:\n{explanation}"
        
        return "Ø£Ø³ØªØ·ÙŠØ¹ Ø´Ø±Ø­: Python, HTML, CSS, JavaScript, Ø§Ù„Ø´Ø¨ÙƒØ§Øª, Ø§Ù„Ø®ÙˆØ§Ø¯Ù…ØŒ ÙˆØºÙŠØ±Ù‡Ø§. Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø´Ø±Ø­Ù‡ØŸ"
    
    def generate_contextual_response(self, message):
        """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ø°ÙƒÙŠ Ø­Ø³Ø¨ Ø§Ù„Ø³ÙŠØ§Ù‚"""
        if not self.conversation_history:
            return "ğŸ§  Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©. Ø£Ø³ØªØ·ÙŠØ¹ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©ØŒ Ø§Ù„Ø´Ø¨ÙƒØ§ØªØŒ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©ØŒ ÙˆØ§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ©."
        
        # ØªØ­Ù„ÙŠÙ„ Ø¢Ø®Ø± Ù…Ø­Ø§Ø¯Ø«Ø©
        last_conversation = self.conversation_history[-1]
        last_message = last_conversation.get('user_message', '')
        
        if "Ø¨Ø±Ù…Ø¬Ø©" in last_message.lower() or "ÙƒÙˆØ¯" in last_message.lower():
            return "ğŸ’» Ù‡Ù„ ØªØ±ÙŠØ¯ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ© ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©ØŸ Ø£Ø³ØªØ·ÙŠØ¹ Ø¥Ù†Ø´Ø§Ø¡ Ø£ÙƒÙˆØ§Ø¯ Ø£Ùˆ Ø´Ø±Ø­ Ù…ÙØ§Ù‡ÙŠÙ…."
        
        elif "Ø´Ø¨ÙƒØ©" in last_message.lower():
            return "ğŸŒ Ù‡Ù„ ØªØ­ØªØ§Ø¬ Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø´Ø¨ÙƒØ§ØªØŸ Ø£Ø³ØªØ·ÙŠØ¹ Ø´Ø±Ø­ TCP/IP, DNS, Ø§Ù„Ø±ÙˆØ§ØªØ±ØŒ ÙˆØºÙŠØ±Ù‡Ø§."
        
        else:
            return "ğŸ¤” Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙˆØ¶ÙŠØ­ Ø³Ø¤Ø§Ù„Ùƒ Ø£ÙƒØ«Ø±ØŸ Ø£Ø³ØªØ·ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ù…ÙˆØ§Ø¶ÙŠØ¹ ØªÙ‚Ù†ÙŠØ© Ù…ØªØ¹Ø¯Ø¯Ø©."
    
    def learn_from_conversation(self, message, response, user_id="default"):
        """Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        if user_id not in self.knowledge["user_profiles"]:
            self.knowledge["user_profiles"][user_id] = {
                "interaction_count": 0,
                "preferences": [],
                "last_interaction": datetime.now().isoformat()
            }
        
        user_data = self.knowledge["user_profiles"][user_id]
        user_data["interaction_count"] += 1
        user_data["last_interaction"] = datetime.now().isoformat()
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        if "Ø¨Ø±Ù…Ø¬Ø©" in message.lower():
            if "Ø¨Ø±Ù…Ø¬Ø©" not in user_data["preferences"]:
                user_data["preferences"].append("Ø¨Ø±Ù…Ø¬Ø©")
        
        self.save_knowledge()
    
    def process_message(self, message, user_id="default"):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
        # ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ø°ÙƒÙŠ
        response = self.generate_ai_response(message)
        
        # Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        self.learn_from_conversation(message, response, user_id)
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        conversation = {
            "timestamp": datetime.now().isoformat(),
            "user_message": message,
            "ai_response": response,
            "user_id": user_id
        }
        self.conversation_history.append(conversation)
        
        return {
            "message": response,
            "analysis": {
                "model_used": "sentence_transformer" if MODEL_LOADED else "basic",
                "response_type": "ai_generated"
            }
        }

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
ai_core = AdvancedAICore()

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/api/chat', methods=['POST'])
def chat_api():
    try:
        data = request.get_json()
        user_message = data.get('message', '')
        user_id = data.get('user_id', 'web_user')
        
        if not user_message:
            return jsonify({'error': 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø±Ø³Ø§Ù„Ø©'}), 400
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        result = ai_core.process_message(user_message, user_id)
        
        return jsonify({
            'response': result['message'],
            'analysis': result['analysis'],
            'model_loaded': MODEL_LOADED,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logging.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {e}")
        return jsonify({'error': 'Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©'}), 500

@app.route('/api/knowledge')
def get_knowledge():
    """Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ÙƒØªØ³Ø¨Ø©"""
    return jsonify({
        'user_profiles': ai_core.knowledge.get('user_profiles', {}),
        'total_conversations': len(ai_core.conversation_history),
        'model_loaded': MODEL_LOADED
    })

@app.route('/api/health')
def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
    return jsonify({
        'status': 'running',
        'model_loaded': MODEL_LOADED,
        'total_knowledge_items': sum(len(qa) for qa in ai_core.knowledge['qa_pairs'].values()),
        'timestamp': datetime.now().isoformat()
    })

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
