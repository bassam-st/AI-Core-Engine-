#!/usr/bin/env python3
# Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© - Ø¥ØµØ¯Ø§Ø± Ù…Ø¹ Ø¯Ù…Ø¬ Ù†Ù…ÙˆØ°Ø¬ Hugging Face + Ø­Ù…Ø§ÙŠØ© ÙˆØ£Ø®Ø·Ø§Ø¡

import os, json, re, time
from datetime import datetime
from flask import Flask, request, jsonify, render_template
import requests

HF_API_KEY = os.getenv("HUGGINGFACE_API_KEY")  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ù…Ø¶Ø§Ù ÙÙŠ Render
# Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø¹Ø§Ù…Ø© ØªØ¹Ù…Ù„ Ø¹Ø¨Ø± Inference API (Ø§Ø®ØªØ± ÙˆØ§Ø­Ø¯)
DEFAULT_HF_MODEL = os.getenv("HF_MODEL", "mistralai/Mistral-7B-Instruct-v0.2")
# Ù…Ù‡Ù„Ø© Ø§Ù„Ø´Ø¨ÙƒØ© Ø­ØªÙ‰ Ù„Ø§ ØªØªØ¬Ù…Ø¯ Ø§Ù„Ù†ÙˆØ§Ø©
HTTP_TIMEOUT = int(os.getenv("HTTP_TIMEOUT", "35"))

app = Flask(__name__)

# ====== Ø·Ø¨Ù‚Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Hugging Face ======
def hf_generate(prompt: str,
                model: str = DEFAULT_HF_MODEL,
                max_new_tokens: int = 256,
                temperature: float = 0.4,
                retries: int = 2) -> str:
    """
    ØªØ³ØªØ¯Ø¹ÙŠ Ù†Ù…ÙˆØ°Ø¬ Hugging Face Ù…Ø¹ ØªØ®ÙÙŠØ¶ Ø§Ù„Ù…Ø®Ø§Ø·Ø±:
    - Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ù† Ø§Ù„Ø¨ÙŠØ¦Ø© ÙÙ‚Ø·
    - Ù…Ù‡Ù„Ø§Øª + Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø¥Ø¹Ø§Ø¯Ø©
    - Ø±Ø³Ø§Ø¦Ù„ Ø®Ø·Ø£ ÙˆØ§Ø¶Ø­Ø© Ø¨Ø¯ÙˆÙ† Ø¥Ø³Ù‚Ø§Ø· Ø§Ù„Ø®Ø¯Ù…Ø©
    """
    if not HF_API_KEY:
        return "âš ï¸ Ù…ÙØªØ§Ø­ HUGGINGFACE_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø©."

    url = f"https://api-inference.huggingface.co/models/{model}"
    headers = {"Authorization": f"Bearer {HF_API_KEY}"}
    payload = {
        "inputs": f"### Instruction:\n{prompt}\n\n### Response:",
        "parameters": {
            "max_new_tokens": max_new_tokens,
            "temperature": temperature,
            "return_full_text": False
        }
    }

    last_err = None
    for _ in range(retries + 1):
        try:
            r = requests.post(url, headers=headers, json=payload, timeout=HTTP_TIMEOUT)
            # 503 ØªØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ­Ù…Ù‘Ù„ Ù„Ù„Ù…Ø±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰Ø› Ù†Ù†ØªØ¸Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ø«Ù… Ù†ÙƒØ±Ø±
            if r.status_code in (503, 524):
                last_err = f"Model warming up (status {r.status_code})"
                time.sleep(3)
                continue
            if r.status_code == 401:
                return "â›” Ù…ÙØªØ§Ø­ Hugging Face ØºÙŠØ± ØµØ§Ù„Ø­ Ø£Ùˆ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©."
            r.raise_for_status()
            data = r.json()
            # ØµÙŠØº Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØªØ®ØªÙ„Ù Ø¨Ø§Ø®ØªÙ„Ø§Ù Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø› Ù†ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ù‹Ø§
            if isinstance(data, list) and data and "generated_text" in data[0]:
                return data[0]["generated_text"].strip()
            if isinstance(data, dict) and "generated_text" in data:
                return data["generated_text"].strip()
            # ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø­ÙŠØ§Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† dicts Ø¯Ø§Ø®Ù„Ù‡Ø§ 'generated_token_count' ÙÙ‚Ø·
            return json.dumps(data, ensure_ascii=False)[:2000]
        except requests.exceptions.Timeout:
            last_err = "â³ Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„."
        except Exception as e:
            last_err = f"â— Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„: {e}"
        time.sleep(1)

    return last_err or "âš ï¸ ØªØ¹Ø°Ù‘Ø± Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„."

# ====== Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ© ======
class SmartAICore:
    def __init__(self):
        self.setup_directories()
        self.load_knowledge()
        self.conversation_memory = []

    def setup_directories(self):
        os.makedirs('knowledge', exist_ok=True)
        os.makedirs('memory', exist_ok=True)

    def load_knowledge(self):
        try:
            with open('knowledge/elite_knowledge.json', 'r', encoding='utf-8') as f:
                self.knowledge = json.load(f)
        except Exception:
            self.knowledge = self.create_basic_knowledge()

    def create_basic_knowledge(self):
        return {
            "expert_qa": {
                "Ø¨Ø±Ù…Ø¬Ø©": {
                    "ÙƒÙŠÙ Ø£Ù†Ø´Ø¦ APIØŸ": "Flask â†’ routes â†’ JSON â†’ test",
                    "Ù…Ø§ Ù‡ÙŠ PythonØŸ": "Ù„ØºØ© Ø¨Ø±Ù…Ø¬Ø© Ù‚ÙˆÙŠØ© ÙˆØ¨Ø³ÙŠØ·Ø© Ù„Ù„ÙˆÙŠØ¨ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆAI",
                    "ÙƒÙŠÙ Ø£Ø¨Ø¯Ø£ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©ØŸ": "Ø§Ø¨Ø¯Ø£ Ø¨Ù€ Python Ø«Ù… Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø«Ù… ØªØ®ØµÙ‘Øµ"
                }
            },
            "code_templates": {
                "python_basic": "print('Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…!')",
                "python_web": "from flask import Flask\napp = Flask(__name__)\n@app.route('/')\ndef home():\n    return 'Ù…Ø±Ø­Ø¨Ø§Ù‹!'\n\nif __name__=='__main__':\n    app.run()",
                "python_calculator": "def add(a,b): return a+b\nprint(add(5,3))"
            }
        }

    def process_message(self, message, user_id="default"):
        msg = message.lower().strip()
        # Ù…Ø´ØºÙ„ ØµØ±ÙŠØ­ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ
        # Ø£Ù…Ø«Ù„Ø©: "Ù†Ù…ÙˆØ°Ø¬: Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨" Ø£Ùˆ "model: summarize ..."
        if msg.startswith("Ù†Ù…ÙˆØ°Ø¬:") or msg.startswith("model:") or "Ø¬Ø±Ù‘Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„" in msg or "Ø´ØºÙ‘Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬" in msg:
            pure = message.split(":", 1)[1].strip() if ":" in message else message
            return hf_generate(pure)

        # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© â†’ ÙƒÙˆØ¯ Ø¬Ø§Ù‡Ø²
        if any(w in msg for w in ["Ø§Ù†Ø´Ø¦", "Ø§ØµÙ†Ø¹", "Ø§ÙƒØªØ¨", "ÙƒÙˆØ¯", "python", "Ø¨Ø§ÙŠØ«ÙˆÙ†"]):
            if any(w in msg for w in ["Ø­Ø³Ø§Ø¨", "Ø¬Ù…Ø¹", "Ø·Ø±Ø­", "Ø¢Ù„Ø© Ø­Ø§Ø³Ø¨Ø©", "calculator"]):
                return self.generate_calculator()
            elif any(w in msg for w in ["Ù…ÙˆÙ‚Ø¹", "ÙˆÙŠØ¨", "web", "ÙÙ„Ø§Ø³Ùƒ", "flask"]):
                return self.generate_web_app()
            elif any(w in msg for w in ["Ø¨ÙˆØª", "Ø¯Ø±Ø¯Ø´Ø©", "chatbot"]):
                return self.generate_chatbot()
            elif any(w in msg for w in ["Ø¨ÙŠØ§Ù†Ø§Øª", "data", "ØªØ­Ù„ÙŠÙ„"]):
                return self.generate_data_analysis()
            else:
                return self.generate_basic_code()

        if any(w in msg for w in ["Ù…Ø³Ø§Ø±", "ØªØ¹Ù„Ù…", "ØªØ¹Ù„ÙŠÙ…"]):
            return self.generate_learning_path()

        if any(w in msg for w in ["Ø±Ø§Ø¬Ø¹", "Ø­Ù„Ù„", "Ø§ÙØ­Øµ Ø§Ù„ÙƒÙˆØ¯"]):
            code = self.extract_code(message)
            return self.code_review(code) if code else "ğŸ“ Ø£Ø±Ø³Ù„ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ù…Ø±Ø§Ø¬Ø¹ØªÙ‡ Ø¨ÙŠÙ† ```"

        if any(w in msg for w in ["ÙÙƒØ±Ø©", "Ù…Ø´Ø±ÙˆØ¹", "Ù…Ù‚ØªØ±Ø­"]):
            return self.generate_project_idea()

        if any(w in msg for w in ["Ø´Ø¹ÙˆØ±", "Ù…Ø´Ø§Ø¹Ø±", "Ø±Ø£ÙŠÙƒ"]):
            return f"ğŸ­ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {self.analyze_sentiment(message)}"

        if any(w in msg for w in ["Ø§Ø¨Ø­Ø«", "Ø¨Ø­Ø«", "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù†"]):
            return self.web_search(message)

        if any(w in msg for w in ["Ù…Ø±Ø­Ø¨", "Ø§Ù‡Ù„Ø§", "Ø³Ù„Ø§Ù…", "hello", "hi"]):
            return self.get_welcome_message()

        # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ: Ø¬Ø±Ù‘Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ Ø£ÙˆÙ„Ù‹Ø§ØŒ Ø«Ù… Ø³Ù‚Ø· Ø¹Ù„Ù‰ Ø±Ø¯ Ù…Ø­Ù„ÙŠ
        cloud = hf_generate(message)
        if cloud and not cloud.startswith(("âš ï¸", "â›”", "â—", "â³")):
            return cloud
        return self.generate_smart_response(message)

    # ======= Ø¨Ø§Ù‚ÙŠ Ù…ÙˆÙ„Ø¯Ø§Øª Ø§Ù„ÙƒÙˆØ¯/Ø§Ù„Ù…Ø­ØªÙˆÙ‰ (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± Ø¬ÙˆÙ‡Ø±ÙŠ) =======
    def generate_calculator(self):
        code = """class Calculator:
    def __init__(self): self.history=[]
    def add(self,a,b): r=a+b; self.history.append(f"{a}+{b}={r}"); return r
    def subtract(self,a,b): r=a-b; self.history.append(f"{a}-{b}={r}"); return r
    def multiply(self,a,b): r=a*b; self.history.append(f"{a}Ã—{b}={r}"); return r
    def divide(self,a,b):
        if b==0: return "Ø®Ø·Ø£: Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±"
        r=a/b; self.history.append(f"{a}Ã·{b}={r}"); return r
    def show_history(self): print("\\n".join(self.history))

calc=Calculator(); print("10+5=",calc.add(10,5)); calc.show_history()"""
        return f"ğŸ§® ÙƒÙˆØ¯ Ø¢Ù„Ø© Ø­Ø§Ø³Ø¨Ø©:\n\n```python\n{code}\n```"

    def generate_web_app(self):
        code = """from flask import Flask
app=Flask(__name__)
@app.route('/')
def home():
    return '<h1>Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ! ğŸŒŸ</h1><p>Ù‡Ø°Ø§ ØªØ·Ø¨ÙŠÙ‚ Flask Ø¨Ø³ÙŠØ·.</p>'
if __name__=='__main__': app.run()"""
        return f"ğŸŒ ÙƒÙˆØ¯ ØªØ·Ø¨ÙŠÙ‚ ÙˆÙŠØ¨:\n\n```python\n{code}\n```"

    def generate_chatbot(self):
        code = """class ChatBot:
    def __init__(self):
        self.responses={'Ù…Ø±Ø­Ø¨Ø§Ù‹':'Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹!','ÙƒÙŠÙ Ø§Ù„Ø­Ø§Ù„':'Ø£Ù†Ø§ Ø¨Ø®ÙŠØ± ğŸ˜Š','Ù…Ø§ Ø§Ø³Ù…Ùƒ':'Ø£Ù†Ø§ Ø¨ÙˆØª Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©!','ÙˆØ¯Ø§Ø¹Ø§Ù‹':'Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ø©!'}
    def respond(self,msg):
        m=msg.lower()
        for k,v in self.responses.items():
            if k in m: return v
        return 'Ù‡Ù„ ØªÙˆØ¶Ø­ Ø³Ø¤Ø§Ù„Ùƒ Ø£ÙƒØ«Ø±ØŸ'
bot=ChatBot(); print(bot.respond('Ù…Ø±Ø­Ø¨Ø§Ù‹'))"""
        return f"ğŸ¤– ÙƒÙˆØ¯ Ø¨ÙˆØª Ø¯Ø±Ø¯Ø´Ø©:\n\n```python\n{code}\n```"

    def generate_data_analysis(self):
        code = """import pandas as pd, matplotlib.pyplot as plt
df=pd.DataFrame({'Ø§Ù„Ø´Ù‡Ø±':['ÙŠÙ†Ø§ÙŠØ±','ÙØ¨Ø±Ø§ÙŠØ±','Ù…Ø§Ø±Ø³','Ø£Ø¨Ø±ÙŠÙ„'],'Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª':[120,150,180,200]})
print(df); print(df.describe()); df.plot(x='Ø§Ù„Ø´Ù‡Ø±',y='Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª',marker='o'); plt.show()"""
        return f"ğŸ“Š ÙƒÙˆØ¯ ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª:\n\n```python\n{code}\n```"

    def generate_basic_code(self):
        code = """def calculate(a,b):
    print(f"{a}+{b}={a+b}"); print(f"{a}-{b}={a-b}"); print(f"{a}Ã—{b}={a*b}")
    if b!=0: print(f"{a}Ã·{b}={a/b}")
with open('example.txt','w',encoding='utf-8') as f: f.write('Ù…Ø±Ø­Ø¨Ø§Ù‹!\\n')
calculate(10,5)"""
        return f"ğŸ’» ÙƒÙˆØ¯ Python Ø£Ø³Ø§Ø³ÙŠ:\n\n```python\n{code}\n```"

    def generate_learning_path(self):
        return "ğŸ¯ Ù…Ø³Ø§Ø± ØªØ¹Ù„Ù…: Ø£Ø³Ø§Ø³ÙŠØ§Øª Python â†’ Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª â†’ OOP â†’ Flask/APIs â†’ Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª â†’ Ù…Ø´Ø§Ø±ÙŠØ¹ Ø¹Ù…Ù„ÙŠØ©"

    def code_review(self, code):
        issues=[]
        if not code: return "Ø£Ø±Ø³Ù„ Ø§Ù„ÙƒÙˆØ¯ Ø¨ÙŠÙ† ```"
        low=code.lower()
        if "password" in low and "encrypt" not in low: issues.append("ğŸ”’ Ø´ÙÙ‘Ø± ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙˆØ±.")
        if "select *" in low: issues.append("ğŸ—ƒï¸ ØªØ¬Ù†Ù‘Ø¨ SELECT *.")
        if "eval(" in low: issues.append("âš ï¸ ØªØ¬Ù†Ù‘Ø¨ eval().")
        return "ğŸ” Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙƒÙˆØ¯:\n" + ("\n".join(issues) if issues else "âœ… Ù„Ø§ Ù…Ø´Ø§ÙƒÙ„ ÙˆØ§Ø¶Ø­Ø©.")

    def generate_project_idea(self):
        return "ğŸ’¡ ÙÙƒØ±Ø©: Ù†Ø¸Ø§Ù… Ù…Ù‡Ø§Ù… Ù…Ø¹ Ø¥Ø´Ø¹Ø§Ø±Ø§Øª ÙˆØªÙ‚Ø±ÙŠØ± Ø£Ø³Ø¨ÙˆØ¹ÙŠ."

    def analyze_sentiment(self, text):
        pos = any(w in text for w in ['Ø¬ÙŠØ¯','Ù…Ù…ØªØ§Ø²','Ø±Ø§Ø¦Ø¹','Ø¬Ù…ÙŠÙ„'])
        neg = any(w in text for w in ['Ø³ÙŠØ¡','Ù…Ø´ÙƒÙ„Ø©','Ø®Ø·Ø£','Ù„Ø§ ÙŠØ¹Ù…Ù„'])
        if pos and not neg: return "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ ğŸ˜Š"
        if neg and not pos: return "Ø³Ù„Ø¨ÙŠ ğŸ˜”"
        return "Ù…Ø­Ø§ÙŠØ¯ ğŸ˜"

    def web_search(self, query):
        topics={"Ø¨Ø±Ù…Ø¬Ø©":"Python, AI, Web3","Ø´Ø¨ÙƒØ§Øª":"5G, IoT, Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ","Ø£Ù†Ø¸Ù…Ø©":"Containers, Kubernetes, DevOps"}
        for t,info in topics.items():
            if t in query: return f"ğŸ” {t}: {info}"
        return "ğŸ” Ø¬Ø±Ù‘Ø¨ ÙƒÙ„Ù…Ø§Øª: Ø¨Ø±Ù…Ø¬Ø© / Ø´Ø¨ÙƒØ§Øª / Ø£Ù†Ø¸Ù…Ø©"

    def get_welcome_message(self):
        return "ğŸš€ Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø°ÙƒÙŠØ©! Ø§ÙƒØªØ¨: Â«Ù†Ù…ÙˆØ°Ø¬: Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨ Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø³Ø§Ù…Â» Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„."

    def generate_smart_response(self, message):
        return f"ğŸ¤” Ø·Ù„Ø¨Øª: Â«{message}Â». ÙŠÙ…ÙƒÙ†Ùƒ Ù‚ÙˆÙ„: Â«Ù†Ù…ÙˆØ°Ø¬: â€¦Â» Ø£Ùˆ Â«Ø£Ù†Ø´Ø¦ ÙƒÙˆØ¯ â€¦Â»."

    def extract_code(self, message):
        blocks=re.findall(r'```[\\w]*\\n(.*?)\\n```', message, re.DOTALL)
        return blocks[0] if blocks else None

# ====== ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†ÙˆØ§Ø© ======
ai_core = SmartAICore()

# ====== Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ======
@app.route('/')
def home():
    # ØµÙØ­Ø© Ø¨Ø³ÙŠØ·Ø© (Ù„Ùˆ Ù„Ø¯ÙŠÙƒ templates/index.html Ø³ÙŠØ¹Ù…Ù„ render_template)
    try:
        return render_template('index.html')
    except Exception:
        return "<h2>Bassam AI Core</h2><p>Ø£Ø±Ø³Ù„ POST Ø¥Ù„Ù‰ /api/chat Ø£Ùˆ /api/generate</p>"

@app.route('/api/chat', methods=['POST'])
def chat_api():
    try:
        data = request.get_json(force=True)
        user_message = (data.get('message') or "").strip()
        if not user_message:
            return jsonify({'error': 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø±Ø³Ø§Ù„Ø©'}), 400
        result = ai_core.process_message(user_message)
        return jsonify({'response': result, 'timestamp': datetime.now().isoformat()})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# Ù…Ø³Ø§Ø± Ù…Ø¨Ø§Ø´Ø± Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª/Ø§Ù„ÙØ±ÙˆÙ†Øª)
@app.route('/api/generate', methods=['POST'])
def generate_api():
    data = request.get_json(force=True)
    prompt = (data.get("prompt") or "").strip()
    model = (data.get("model") or DEFAULT_HF_MODEL).strip()
    if not prompt:
        return jsonify({"error": "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ prompt"}), 400
    text = hf_generate(prompt, model=model)
    return jsonify({"model": model, "output": text, "ts": datetime.now().isoformat()})

@app.route('/health')
def health_check():
    return jsonify({'status': 'running', 'version': 'smart_hf_2.1', 'model': DEFAULT_HF_MODEL})

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
