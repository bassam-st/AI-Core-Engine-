#!/usr/bin/env python3
# Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© - Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù†Ø®Ø¨Ø©

import os
import json
import logging
import requests
import re
import base64
import hashlib
from datetime import datetime, timedelta
from flask import Flask, request, jsonify, render_template
import numpy as np
import nltk
from sentence_transformers import SentenceTransformer, util
import matplotlib.pyplot as plt
import io
import csv
import sqlite3

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
try:
    semantic_model = SentenceTransformer('all-MiniLM-L6-v2')
    MODEL_LOADED = True
    print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ø¨Ù†Ø¬Ø§Ø­!")
except Exception as e:
    print(f"âš ï¸  ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©: {e}")
    MODEL_LOADED = False

app = Flask(__name__)

class EliteAICore:
    def __init__(self):
        self.setup_directories()
        self.load_advanced_knowledge()
        self.setup_nltk()
        self.conversation_memory = []
        self.user_profiles = {}
        
    def setup_directories(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"""
        dirs = ['knowledge', 'memory', 'models', 'cache', 'projects', 'uploads']
        for dir_name in dirs:
            os.makedirs(dir_name, exist_ok=True)
    
    def setup_nltk(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ NLTK Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
        try:
            nltk.data.find('tokenizers/punkt')
            nltk.data.find('corpora/stopwords')
        except LookupError:
            nltk.download('punkt')
            nltk.download('stopwords')
    
    def load_advanced_knowledge(self):
        """ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù†Ø®Ø¨Ø©"""
        try:
            with open('knowledge/elite_knowledge.json', 'r', encoding='utf-8') as f:
                self.knowledge = json.load(f)
            print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ø¨Ù†Ø¬Ø§Ø­!")
        except Exception as e:
            print(f"âš ï¸  ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ©: {e}")
            self.knowledge = self.create_elite_knowledge()
    
    def create_elite_knowledge(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù†Ø®Ø¨Ø©"""
        elite_knowledge = {
            "expert_qa": {
                "Ø¨Ø±Ù…Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©": {
                    "ÙƒÙŠÙ Ø£Ù†Ø´Ø¦ API Ù…ØªÙ‚Ø¯Ù…ØŸ": "Ù„Ø¥Ù†Ø´Ø§Ø¡ API Ù…ØªÙ‚Ø¯Ù…: 1) Ø§Ø³ØªØ®Ø¯Ù… FastAPI Ø£Ùˆ Flask-RESTful 2) Ø£Ø¶Ù Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© JWT 3) Ù†ÙØ° rate limiting 4) ÙˆØ«Ù‚ API Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Swagger",
                    "Ù…Ø§ Ù‡ÙŠ microservicesØŸ": "Ù‡Ù†Ø¯Ø³Ø© microservices ØªÙ‚Ø³Ù… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¥Ù„Ù‰ Ø®Ø¯Ù…Ø§Øª ØµØºÙŠØ±Ø© Ù…Ø³ØªÙ‚Ù„Ø©ØŒ ÙƒÙ„ Ø®Ø¯Ù…Ø© ØªØ±ÙƒØ² Ø¹Ù„Ù‰ ÙˆØ¸ÙŠÙØ© Ù…Ø­Ø¯Ø¯Ø© ÙˆØªØªÙˆØ§ØµÙ„ Ø¹Ø¨Ø± APIs.",
                    "ÙƒÙŠÙ Ø£Ø­Ø³Ù† Ø£Ø¯Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŸ": "1) ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ 2) Ø§Ø³ØªØ®Ø¯Ù… queries ÙØ¹Ø§Ù„Ø© 3) Ø§Ø¶Ø¨Ø· Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª cache 4) Ø§Ø³ØªØ®Ø¯Ù… connection pooling",
                    "Ù…Ø§ Ù‡Ùˆ Docker ÙˆÙƒÙŠÙ Ø£Ø³ØªØ®Ø¯Ù…Ù‡ØŸ": "Docker Ù†Ø¸Ø§Ù… containerization ÙŠØ­Ø²Ù… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙˆØ§Ø¹ØªÙ…Ø§Ø¯Ø§ØªÙ‡ ÙÙŠ Ø­Ø§ÙˆÙŠØ© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ Ø£ÙŠ Ù†Ø¸Ø§Ù….",
                    "ÙƒÙŠÙ Ø£Ù†Ø´Ø¦ ØªØ·Ø¨ÙŠÙ‚ ØªØ¹Ù„Ù… Ø¢Ù„ÙŠØŸ": "1) Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª 2) ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª 3) Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ 4) Ø§Ù„ØªØ¯Ø±ÙŠØ¨ 5) Ø§Ù„ØªÙ‚ÙŠÙŠÙ… 6) Ø§Ù„Ù†Ø´Ø±"
                },
                "Ø£Ù…Ù† Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ": {
                    "ÙƒØ£Ø­Ù…ÙŠ Ø®Ø§Ø¯Ù…ÙŠØŸ": "1) ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ø¸Ø§Ù… 2) Ø¬Ø¯Ø§Ø± Ø­Ù…Ø§ÙŠØ© 3) fail2ban 4) ØªØ¹Ø·ÙŠÙ„ login Ø¨Ø§Ù„root 5) Ø§Ø³ØªØ®Ø¯Ø§Ù… SSH keys",
                    "Ù…Ø§ Ù‡ÙŠ Ù‡Ø¬Ù…Ø§Øª DDoSØŸ": "Ù‡Ø¬Ù…Ø§Øª Ø§Ù„Ø­Ø±Ù…Ø§Ù† Ù…Ù† Ø§Ù„Ø®Ø¯Ù…Ø© ØªÙ‡Ø¯Ù Ù„Ø¥ØºØ±Ø§Ù‚ Ø§Ù„Ø®Ø§Ø¯Ù… Ø¨Ø·Ù„Ø¨Ø§Øª Ø²Ø§Ø¦ÙØ© Ù„Ù…Ù†Ø¹ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©.",
                    "ÙƒÙŠÙ Ø£ÙƒØªØ´Ù Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚Ø§ØªØŸ": "Ø±Ø§Ù‚Ø¨ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø£Ù†Ø¸Ù…Ø© ÙƒØ´Ù Ø§Ù„ØªØ³Ù„Ù„ØŒ Ø§ÙØ­Øµ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ØºÙŠØ± Ø§Ù„Ù…Ø¹ØªØ§Ø¯Ø©ØŒ ØªØªØ¨Ø¹ Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ©.",
                    "Ù…Ø§ Ù‡Ùˆ penetration testingØŸ": "Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚ Ù‡Ùˆ Ù…Ø­Ø§ÙƒØ§Ø© Ù‡Ø¬Ù…Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…."
                },
                "Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ": {
                    "Ù…Ø§ Ù‡Ùˆ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† AI Ùˆ MLØŸ": "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ÙÙ‡ÙˆÙ… Ø£ÙˆØ³Ø¹ØŒ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø¬Ø²Ø¡ Ù…Ù†Ù‡ ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ ØªØ¹Ù„Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.",
                    "ÙƒÙŠÙ Ø£Ø¹Ù…Ù„ Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø¹Ù…ÙŠÙ‚ØŸ": "1) TensorFlow/PyTorch 2) Ø¨Ù†Ø§Ø¡ architecture 3) ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ 4) Ø¶Ø¨Ø· hyperparameters 5) Ø§Ù„ØªÙ‚ÙŠÙŠÙ…",
                    "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ©ØŸ": "Ù…Ø­Ø§ÙƒØ§Ø© Ù„Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ø¨Ø´Ø±ÙŠØŒ ØªØªÙƒÙˆÙ† Ù…Ù† Ø·Ø¨Ù‚Ø§Øª Ø¹ØµØ¨ÙˆÙ†ÙŠØ© ØªØªØ¹Ù„Ù… Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."
                }
            },
            "code_templates": {
                "python_ai_chatbot": """import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import json

class AdvancedChatBot:
    def __init__(self):
        self.vectorizer = TfidfVectorizer()
        self.knowledge_base = {
            'greetings': ['Ù…Ø±Ø­Ø¨Ø§Ù‹', 'Ø£Ù‡Ù„Ø§Ù‹', 'Ø§Ù‡Ù„Ø§ÙˆØ³Ù‡Ù„Ø§'],
            'questions': {
                'Ù…Ø§ Ù‡Ùˆ Ø§Ø³Ù…Ùƒ': 'Ø£Ù†Ø§ Ø¨ÙˆØª Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø°ÙƒÙŠ!',
                'ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ': 'Ø£Ù†Ø§ Ø¨Ø®ÙŠØ±ØŒ Ø´ÙƒØ±Ø§Ù‹ Ù„Ø³Ø¤Ø§Ù„Ùƒ!'
            }
        }
    
    def respond(self, message):
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ø³ÙŠØ·
        if any(greet in message for greet in self.knowledge_base['greetings']):
            return 'Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ'
        
        for question, answer in self.knowledge_base['questions'].items():
            if question in message:
                return answer
        
        return 'Ù‡Ø°Ø§ Ø³Ø¤Ø§Ù„ Ù…Ø«ÙŠØ± Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù…! Ø¯Ø¹Ù†ÙŠ Ø£ÙÙƒØ± ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø§Ø³Ø¨Ø©.'

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙˆØª
bot = AdvancedChatBot()
print(bot.respond('Ù…Ø±Ø­Ø¨Ø§Ù‹'))""",

                "react_components": """import React, { useState, useEffect } from 'react';
import './App.css';

function AdvancedApp() {
  const [data, setData] = useState([]);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    fetch('/api/data')
      .then(response => response.json())
      .then(data => {
        setData(data);
        setLoading(false);
      });
  }, []);

  if (loading) return <div>Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„...</div>;

  return (
    <div className="app">
      <h1>ØªØ·Ø¨ÙŠÙ‚ React Ù…ØªÙ‚Ø¯Ù…</h1>
      <div className="data-grid">
        {data.map(item => (
          <div key={item.id} className="card">
            <h3>{item.title}</h3>
            <p>{item.description}</p>
          </div>
        ))}
      </div>
    </div>
  );
}

export default AdvancedApp;""",

                "nodejs_api": """const express = require('express');
const jwt = require('jsonwebtoken');
const bcrypt = require('bcrypt');
const app = express();

app.use(express.json());

// Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¤Ù‚ØªØ©
const users = [];
const posts = [];

// middleware Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©
const authenticateToken = (req, res, next) => {
  const authHeader = req.headers['authorization'];
  const token = authHeader && authHeader.split(' ')[1];

  if (!token) {
    return res.status(401).json({ error: 'Ø§Ù„ÙˆØµÙˆÙ„ Ù…Ø±ÙÙˆØ¶' });
  }

  jwt.verify(token, process.env.JWT_SECRET, (err, user) => {
    if (err) return res.status(403).json({ error: 'Ø±Ù…Ø² ØºÙŠØ± ØµØ§Ù„Ø­' });
    req.user = user;
    next();
  });
};

// routes
app.post('/register', async (req, res) => {
  try {
    const hashedPassword = await bcrypt.hash(req.body.password, 10);
    const user = { 
      id: users.length + 1, 
      username: req.body.username, 
      password: hashedPassword 
    };
    users.push(user);
    res.status(201).json({ message: 'ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø­Ø³Ø§Ø¨ Ø¨Ù†Ø¬Ø§Ø­' });
  } catch {
    res.status(500).json({ error: 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…' });
  }
});

app.listen(3000, () => {
  console.log('Ø§Ù„Ø®Ø§Ø¯Ù… ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ port 3000');
});"""
            },
            "learning_paths": {
                "Ù…Ø·ÙˆØ± ÙˆÙŠØ¨ Ù…ØªÙƒØ§Ù…Ù„": [
                    "HTML5 & CSS3 Ø§Ù„Ù…ØªÙ‚Ø¯Ù…",
                    "JavaScript ES6+",
                    "React Ø£Ùˆ Vue.js", 
                    "Node.js Ùˆ Express",
                    "Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª SQL/NoSQL",
                    "DevOps ÙˆØ§Ù„Ù†Ø´Ø±"
                ],
                "Ø®Ø¨ÙŠØ± Ø£Ù…Ù† Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ": [
                    "Ø£Ø³Ø§Ø³ÙŠØ§Øª Ø§Ù„Ø´Ø¨ÙƒØ§Øª",
                    "Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„",
                    "Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø£Ù…Ù†",
                    "Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚",
                    "ØªØ­Ù‚ÙŠÙ‚ Ø¬Ø±Ø§Ø¦Ù… Ø±Ù‚Ù…ÙŠØ©",
                    "ØªØ£Ù…ÙŠÙ† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©"
                ],
                "Ù…Ù‡Ù†Ø¯Ø³ ØªØ¹Ù„Ù… Ø¢Ù„ÙŠ": [
                    "Python Ù„Ù„Ø¥Ø­ØµØ§Ø¡",
                    "Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ",
                    "Ù…ÙƒØªØ¨Ø§Øª ML (scikit-learn)",
                    "Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚",
                    "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©",
                    "Ù†Ø´Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"
                ]
            }
        }
        
        self.save_knowledge(elite_knowledge)
        return elite_knowledge
    
    def save_knowledge(self, knowledge=None):
        """Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
        if knowledge is None:
            knowledge = self.knowledge
        
        try:
            with open('knowledge/elite_knowledge.json', 'w', encoding='utf-8') as f:
                json.dump(knowledge, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ÙØ¸: {e}")
    
    def web_search_simulation(self, query):
        """Ù…Ø­Ø§ÙƒØ§Ø© Ø¨Ø­Ø« ÙˆÙŠØ¨ Ø°ÙƒÙŠ"""
        search_results = {
            "Ø£Ø­Ø¯Ø« ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© 2024": "Ø£Ù‡Ù… Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª: 1) AI-assisted coding 2) Low-code platforms 3) WebAssembly 4) Serverless architecture 5) Edge computing",
            "Ù…Ø³ØªÙ‚Ø¨Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ": "Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª: 1) Generative AI 2) Multimodal models 3) AI ethics 4) Quantum machine learning 5) Autonomous systems",
            "Ø£ÙØ¶Ù„ Ù…Ù…Ø§Ø±Ø³Ø§Øª Ø§Ù„Ø£Ù…Ù†": "1) Zero Trust Architecture 2) Multi-factor authentication 3) Regular security audits 4) Employee training 5) Incident response planning"
        }
        
        for topic, content in search_results.items():
            if any(word in query for word in topic.split()):
                return f"ğŸ” Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† '{query}':\n\n{content}"
        
        return f"ğŸ” Ù„Ù… Ø£Ø¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù€ '{query}'. Ø¬Ø±Ø¨ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: Ø£Ø­Ø¯Ø« ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©ØŒ Ù…Ø³ØªÙ‚Ø¨Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ø£Ùˆ Ø£ÙØ¶Ù„ Ù…Ù…Ø§Ø±Ø³Ø§Øª Ø§Ù„Ø£Ù…Ù†."
    
    def analyze_sentiment(self, text):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù†Øµ"""
        positive_words = ['Ø¬ÙŠØ¯', 'Ù…Ù…ØªØ§Ø²', 'Ø±Ø§Ø¦Ø¹', 'Ø´ÙƒØ±Ø§', 'Ø¬Ù…ÙŠÙ„', 'Ù…Ø°Ù‡Ù„']
        negative_words = ['Ø³ÙŠØ¡', 'Ù…Ø´ÙƒÙ„Ø©', 'Ø®Ø·Ø£', 'Ù„Ø§ ÙŠØ¹Ù…Ù„', 'ØµØ¹Ø¨', 'Ù…Ø¹Ù‚Ø¯']
        
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        
        if positive_count > negative_count:
            return "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ"
        elif negative_count > positive_count:
            return "Ø³Ù„Ø¨ÙŠ"
        else:
            return "Ù…Ø­Ø§ÙŠØ¯"
    
    def generate_learning_path(self, topic, level="Ù…Ø¨ØªØ¯Ø¦"):
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ø³Ø§Ø± ØªØ¹Ù„Ù… Ù…Ø®ØµØµ"""
        paths = {
            "Ø¨Ø±Ù…Ø¬Ø©": {
                "Ù…Ø¨ØªØ¯Ø¦": ["Ù…Ù‚Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©", "Ø£Ø³Ø§Ø³ÙŠØ§Øª Python", "Ù…Ø´Ø§Ø±ÙŠØ¹ Ø¨Ø³ÙŠØ·Ø©", "ØªØ¹Ù„Ù… Git"],
                "Ù…ØªÙˆØ³Ø·": ["Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "APIs", "Ù…Ø´Ø§Ø±ÙŠØ¹ Ù…ØªÙˆØ³Ø·Ø©"],
                "Ù…ØªÙ‚Ø¯Ù…": ["Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ§Øª", "Ø§Ù„ØªØµÙ…ÙŠÙ… patterns", "Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª", "Ù…Ø´Ø§Ø±ÙŠØ¹ Ù…Ø¹Ù‚Ø¯Ø©"]
            },
            "Ø´Ø¨ÙƒØ§Øª": {
                "Ù…Ø¨ØªØ¯Ø¦": ["Ø£Ø³Ø§Ø³ÙŠØ§Øª Ø§Ù„Ø´Ø¨ÙƒØ§Øª", "Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ TCP/IP", "Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø´Ø¨ÙƒØ©", "ØªØµÙ…ÙŠÙ… Ø´Ø¨ÙƒØ§Øª ØµØºÙŠØ±Ø©"],
                "Ù…ØªÙˆØ³Ø·": ["Ø´Ø¨ÙƒØ§Øª enterprise", "Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø´Ø¨ÙƒÙŠ", "Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„Ø§Øª Ø§Ù„ØªÙˆØ¬ÙŠÙ‡", "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø´Ø¨ÙƒØ§Øª"],
                "Ù…ØªÙ‚Ø¯Ù…": ["Ø´Ø¨ÙƒØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©", "virtualization", "SDN", "Ø£Ù…Ù† Ù…ØªÙ‚Ø¯Ù…"]
            }
        }
        
        if topic in paths and level in paths[topic]:
            path = paths[topic][level]
            return f"ğŸ¯ Ù…Ø³Ø§Ø± ØªØ¹Ù„Ù… {topic} Ù„Ù„Ù…Ø³ØªÙˆÙ‰ {level}:\n\n" + "\n".join([f"â€¢ {item}" for item in path])
        
        return f"Ø£Ø³ØªØ·ÙŠØ¹ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³Ø§Ø±Ø§Øª ØªØ¹Ù„Ù… Ù„Ù„Ø¨Ø±Ù…Ø¬Ø©ØŒ Ø§Ù„Ø´Ø¨ÙƒØ§ØªØŒ Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠØŒ ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. Ø£ÙŠ Ù…Ø¬Ø§Ù„ ØªÙØ¶Ù„ØŸ"
    
    def code_review(self, code):
        """Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯"""
        issues = []
        
        # ÙØ­Øµ Ø£Ø®Ø·Ø§Ø¡ Ø´Ø§Ø¦Ø¹Ø©
        if "import os" in code and "subprocess" in code:
            issues.append("âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø§Øª Ù†Ø¸Ø§Ù… Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ ØªØ­Ù‚Ù‚ Ø£Ù…Ù†ÙŠ")
        
        if "password" in code.lower() and "encrypt" not in code.lower():
            issues.append("ğŸ”’ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙˆØ± ÙŠØ¬Ø¨ ØªØ´ÙÙŠØ±Ù‡Ø§")
        
        if "select *" in code.lower():
            issues.append("ğŸ—ƒï¸ ØªØ¬Ù†Ø¨ SELECT *ØŒ Ø­Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙ‚Ø·")
        
        if issues:
            return "ğŸ” Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙƒÙˆØ¯:\n" + "\n".join(issues)
        else:
            return "âœ… Ø§Ù„ÙƒÙˆØ¯ ÙŠØ¨Ø¯Ùˆ Ø¬ÙŠØ¯Ø§Ù‹! Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø´Ø§ÙƒÙ„ ÙˆØ§Ø¶Ø­Ø©."
    
    def generate_project_idea(self, field, complexity="medium"):
        """ØªÙˆÙ„ÙŠØ¯ Ø£ÙÙƒØ§Ø± Ù…Ø´Ø§Ø±ÙŠØ¹"""
        projects = {
            "Ø¨Ø±Ù…Ø¬Ø©": {
                "easy": ["Ø¢Ù„Ø© Ø­Ø§Ø³Ø¨Ø©", "Ù‚Ø§Ø¦Ù…Ø© Ù…Ù‡Ø§Ù…", "Ù…Ø­ÙˆÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª", "ØªØ·Ø¨ÙŠÙ‚ Ø·Ù‚Ø³"],
                "medium": ["Ù…Ù†ØµØ© Ù…Ø¯ÙˆÙ†Ø©", "Ù…ØªØ¬Ø± Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ", "Ù†Ø¸Ø§Ù… Ø­Ø¬ÙˆØ²Ø§Øª", "ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø±Ø¯Ø´Ø©"],
                "hard": ["Ù…Ù†ØµØ© ØªØ¹Ù„Ù…", "Ù†Ø¸Ø§Ù… ØªÙˆØµÙŠØ§Øª", "Ø¨ÙˆØª Ø°ÙƒÙŠ", "ØªØ·Ø¨ÙŠÙ‚ ØªØ¹Ù„Ù… Ø¢Ù„ÙŠ"]
            },
            "Ø´Ø¨ÙƒØ§Øª": {
                "easy": ["Ù…Ø§Ø³Ø­ Ø´Ø¨ÙƒØ©", "Ø£Ø¯Ø§Ø© ping Ù…ØªÙ‚Ø¯Ù…Ø©", "Ù…Ø­Ù„Ù„ Ø­Ø²Ù… Ø¨Ø³ÙŠØ·"],
                "medium": ["Ø¬Ø¯Ø§Ø± Ø­Ù…Ø§ÙŠØ©", "Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© Ø´Ø¨ÙƒØ©", "Ø®Ø§Ø¯Ù… VPN"],
                "hard": ["Ù†Ø¸Ø§Ù… ÙƒØ´Ù ØªØ³Ù„Ù„", "Ø´Ø¨ÙƒØ© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©", "Ù…Ù†ØµØ© Ø£Ù…Ù† Ù…ØªÙƒØ§Ù…Ù„Ø©"]
            }
        }
        
        if field in projects and complexity in projects[field]:
            ideas = projects[field][complexity]
            idea = np.random.choice(ideas)
            return f"ğŸ’¡ ÙÙƒØ±Ø© Ù…Ø´Ø±ÙˆØ¹ {field} ({complexity}):\n\n{idea}\n\nÙ…Ø³ØªÙˆÙ‰ Ø§Ù„ØµØ¹ÙˆØ¨Ø©: {complexity}"
        
        return "Ø£Ø³ØªØ·ÙŠØ¹ Ø§Ù‚ØªØ±Ø§Ø­ Ù…Ø´Ø§Ø±ÙŠØ¹ ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©ØŒ Ø§Ù„Ø´Ø¨ÙƒØ§ØªØŒ Ø§Ù„Ø£Ù…Ù†ØŒ ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ."
    
    def process_advanced_message(self, message, user_id="default"):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ø±Ø³Ø§Ø¦Ù„"""
        message_lower = message.lower()
        
        # ØªØ­Ø¯ÙŠØ« Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        self.update_user_profile(user_id, message)
        
        # ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…
        sentiment = self.analyze_sentiment(message)
        intent = self.analyze_advanced_intent(message)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ù…ØªÙ‚Ø¯Ù…
        if "Ø§Ø¨Ø­Ø« Ø¹Ù†" in message or "Ù…Ø§ Ù‡ÙŠ Ø¢Ø®Ø±" in message:
            response = self.web_search_simulation(message)
        
        elif "Ù…Ø³Ø§Ø± ØªØ¹Ù„Ù…" in message or "ÙƒÙŠÙ Ø£ØªØ¹Ù„Ù…" in message:
            topic = self.extract_topic(message)
            level = "Ù…Ø¨ØªØ¯Ø¦" if "Ù…Ø¨ØªØ¯Ø¦" in message else "Ù…ØªÙˆØ³Ø·"
            response = self.generate_learning_path(topic, level)
        
        elif "Ø±Ø§Ø¬Ø¹ Ø§Ù„ÙƒÙˆØ¯" in message or "Ø­Ù„Ù„ Ø§Ù„ÙƒÙˆØ¯" in message:
            code = self.extract_code(message)
            response = self.code_review(code) if code else "Ø£Ø±Ø³Ù„ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ù…Ø±Ø§Ø¬Ø¹ØªÙ‡"
        
        elif "ÙÙƒØ±Ø© Ù…Ø´Ø±ÙˆØ¹" in message:
            field = self.extract_field(message)
            complexity = "medium"
            response = self.generate_project_idea(field, complexity)
        
        elif "Ø£Ù†Ø´Ø¦ Ù„ÙŠ" in message and "ÙƒÙˆØ¯" in message:
            response = self.generate_elite_code(message)
        
        else:
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø®Ø¨ÙŠØ±Ø©
            answer = self.find_expert_answer(message)
            response = answer if answer else self.generate_creative_response(message, sentiment)
        
        # Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        self.save_to_memory(user_id, message, response, intent, sentiment)
        
        return {
            "message": response,
            "analysis": {
                "intent": intent,
                "sentiment": sentiment,
                "user_level": self.get_user_level(user_id),
                "response_type": "advanced_ai"
            }
        }
    
    def extract_topic(self, message):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ù„Ø©"""
        topics = ["Ø¨Ø±Ù…Ø¬Ø©", "Ø´Ø¨ÙƒØ§Øª", "Ø£Ù…Ù†", "Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª"]
        for topic in topics:
            if topic in message:
                return topic
        return "Ø¨Ø±Ù…Ø¬Ø©"
    
    def extract_field(self, message):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¬Ø§Ù„ Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ù„Ø©"""
        fields = ["Ø¨Ø±Ù…Ø¬Ø©", "Ø´Ø¨ÙƒØ§Øª", "Ø£Ù…Ù†", "ÙˆÙŠØ¨", "Ø¬ÙˆØ§Ù„"]
        for field in fields:
            if field in message:
                return field
        return "Ø¨Ø±Ù…Ø¬Ø©"
    
    def extract_code(self, message):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙˆØ¯ Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ù„Ø©"""
        code_blocks = re.findall(r'```[\w]*\n(.*?)\n```', message, re.DOTALL)
        return code_blocks[0] if code_blocks else None
    
    def find_expert_answer(self, question):
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø®Ø¨ÙŠØ±Ø©"""
        best_score = 0
        best_answer = None
        
        for category, qa_pairs in self.knowledge["expert_qa"].items():
            for q, a in qa_pairs.items():
                score = self.semantic_similarity(question, q)
                if score > best_score and score > 0.4:
                    best_score = score
                    best_answer = f"ğŸ“ {a}"
        
        return best_answer
    
    def generate_elite_code(self, message):
        """ØªÙˆÙ„ÙŠØ¯ Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù†Ø®Ø¨Ø©"""
        message_lower = message.lower()
        
        if any(word in message_lower for word in ["Ø¨ÙˆØª", "chatbot", "Ø¯Ø±Ø¯Ø´Ø©"]):
            return f"ğŸ¤– ÙƒÙˆØ¯ Ø¨ÙˆØª Ø°ÙƒÙŠ Ù…ØªÙ‚Ø¯Ù…:\n\n```python\n{self.knowledge['code_templates']['python_ai_chatbot']}\n```"
        
        elif any(word in message_lower for word in ["react", "ÙˆØ§Ø¬Ù‡Ø©", "frontend"]):
            return f"âš›ï¸ ÙƒÙˆØ¯ React Ù…ØªÙ‚Ø¯Ù…:\n\n```jsx\n{self.knowledge['code_templates']['react_components']}\n```"
        
        elif any(word in message_lower for word in ["api", "Ø®Ø§Ø¯Ù…", "server"]):
            return f"ğŸ”— ÙƒÙˆØ¯ Node.js API Ù…ØªÙ‚Ø¯Ù…:\n\n```javascript\n{self.knowledge['code_templates']['nodejs_api']}\n```"
        
        else:
            return "Ø£Ø³ØªØ·ÙŠØ¹ Ø¥Ù†Ø´Ø§Ø¡: Ø¨ÙˆØªØ§Øª Ø°ÙƒÙŠØ©ØŒ ÙˆØ§Ø¬Ù‡Ø§Øª ReactØŒ APIs Ù…ØªÙ‚Ø¯Ù…Ø©ØŒ ÙˆØ£Ù†Ø¸Ù…Ø© Ù…Ø¹Ù‚Ø¯Ø©. Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø¨Ø§Ù„Ø¶Ø¨Ø·ØŸ"
    
    def generate_creative_response(self, message, sentiment):
        """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ÙˆØ¯ Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©"""
        creative_responses = [
            "ğŸ¤” Ù‡Ø°Ø§ Ø³Ø¤Ø§Ù„ Ø¹Ù…ÙŠÙ‚! Ø¯Ø¹Ù†ÙŠ Ø£ÙÙƒØ± ÙÙŠ Ø£ÙØ¶Ù„ Ø·Ø±ÙŠÙ‚Ø© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©...",
            "ğŸ¯ Ø£Ø±Ù‰ Ø£Ù†Ùƒ ØªØ¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ø±ÙØ© Ù…ØªÙ‚Ø¯Ù…Ø©. Ù‡Ø°Ø§ Ù…Ù…ØªØ§Ø²!",
            "ğŸ’¡ ÙÙƒØ±Ø© Ø±Ø§Ø¦Ø¹Ø©! Ù‡Ù„ ØªØ±ÙŠØ¯Ù†ÙŠ Ø£Ù† Ø£Ø¹Ù…Ù‚ Ø£ÙƒØ«Ø± ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ØŸ",
            "ğŸš€ Ù‡Ø°Ø§ ÙŠØ°ÙƒØ±Ù†ÙŠ Ø¨ØªÙ‚Ù†ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ø§Ù„. Ù‡Ù„ ØªØ±ÙŠØ¯ Ø§Ø³ØªÙƒØ´Ø§ÙÙ‡Ø§ØŸ",
            "ğŸ” Ø³Ø£Ø¨Ø­Ø« ÙÙŠ Ø£Ø­Ø¯Ø« Ø§Ù„ØªØ·ÙˆØ±Ø§Øª Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ ÙˆØ£Ø¹ÙˆØ¯ Ø¥Ù„ÙŠÙƒ Ø¨Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø´Ø§Ù…Ù„Ø©."
        ]
        
        return np.random.choice(creative_responses) + f"\n\n(ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {sentiment})"
    
    def analyze_advanced_intent(self, message):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
        message_lower = message.lower()
        
        if any(word in message_lower for word in ["Ø§Ø¨Ø­Ø«", "Ø£Ø®Ø¨Ø§Ø±", "Ø¬Ø¯ÙŠØ¯", "Ù…Ø³ØªØ¬Ø¯"]):
            return "Ø¨Ø­Ø«_Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"
        elif any(word in message_lower for word in ["Ù…Ø³Ø§Ø±", "ØªØ¹Ù„Ù…", "ÙƒÙˆØ±Ø³", "Ø¯ÙˆØ±Ø©"]):
            return "ØªØ¹Ù„Ù…_ÙˆØªØ·ÙˆÙŠØ±"
        elif any(word in message_lower for word in ["Ø±Ø§Ø¬Ø¹", "Ø­Ù„Ù„", "Ø§ÙØ­Øµ", "ÙƒÙˆØ¯"]):
            return "Ù…Ø±Ø§Ø¬Ø¹Ø©_ÙƒÙˆØ¯"
        elif any(word in message_lower for word in ["Ù…Ø´Ø±ÙˆØ¹", "ÙÙƒØ±Ø©", "Ø¨Ù†Ø§Ø¡", "Ø£Ù†Ø´Ø¦"]):
            return "Ø¥Ø¨Ø¯Ø§Ø¹_Ù…Ø´Ø§Ø±ÙŠØ¹"
        elif any(word in message_lower for word in ["ÙƒÙˆØ¯", "Ø¨Ø±Ù…Ø¬Ø©", "Ø³ÙƒØ±ÙŠØ¨Øª"]):
            return "ØªÙˆÙ„ÙŠØ¯_ÙƒÙˆØ¯"
        else:
            return "Ø§Ø³ØªÙØ³Ø§Ø±_Ø¹Ø§Ù…"
    
    def update_user_profile(self, user_id, message):
        """ØªØ­Ø¯ÙŠØ« Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
        if user_id not in self.user_profiles:
            self.user_profiles[user_id] = {
                "join_date": datetime.now().isoformat(),
                "interaction_count": 0,
                "expertise_areas": [],
                "preferred_complexity": "medium",
                "learning_goals": [],
                "last_activity": datetime.now().isoformat()
            }
        
        profile = self.user_profiles[user_id]
        profile["interaction_count"] += 1
        profile["last_activity"] = datetime.now().isoformat()
        
        # ØªØ­Ø¯ÙŠØ« Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ø®Ø¨Ø±Ø©
        areas = ["Ø¨Ø±Ù…Ø¬Ø©", "Ø´Ø¨ÙƒØ§Øª", "Ø£Ù…Ù†", "Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª"]
        for area in areas:
            if area in message and area not in profile["expertise_areas"]:
                profile["expertise_areas"].append(area)
    
    def get_user_level(self, user_id):
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        if user_id not in self.user_profiles:
            return "Ù…Ø¨ØªØ¯Ø¦"
        
        interactions = self.user_profiles[user_id]["interaction_count"]
        if interactions > 50:
            return "Ø®Ø¨ÙŠØ±"
        elif interactions > 20:
            return "Ù…ØªÙˆØ³Ø·"
        else:
            return "Ù…Ø¨ØªØ¯Ø¦"
    
    def save_to_memory(self, user_id, user_message, ai_response, intent, sentiment):
        """Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
        memory_entry = {
            "timestamp": datetime.now().isoformat(),
            "user_id": user_id,
            "user_message": user_message,
            "ai_response": ai_response,
            "intent": intent,
            "sentiment": sentiment,
            "user_level": self.get_user_level(user_id)
        }
        
        self.conversation_memory.append(memory_entry)
        
        # Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„Ù…Ù„Ù
        try:
            with open(f'memory/{user_id}_memory.json', 'w', encoding='utf-8') as f:
                json.dump(self.conversation_memory[-100:], f, ensure_ascii=False, indent=2)
        except:
            pass
    
    def semantic_similarity(self, text1, text2):
        """Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ"""
        if not MODEL_LOADED:
            words1 = set(text1.lower().split())
            words2 = set(text2.lower().split())
            common = words1.intersection(words2)
            return len(common) / max(len(words1), len(words2))
        
        emb1 = semantic_model.encode(text1, convert_to_tensor=True)
        emb2 = semantic_model.encode(text2, convert_to_tensor=True)
        return util.pytorch_cos_sim(emb1, emb2).item()

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ù…ØªØ·ÙˆØ±Ø©
ai_core = EliteAICore()

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/api/chat', methods=['POST'])
def chat_api():
    try:
        data = request.get_json()
        user_message = data.get('message', '')
        user_id = data.get('user_id', 'web_user')
        
        if not user_message:
            return jsonify({'error': 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø±Ø³Ø§Ù„Ø©'}), 400
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©
        result = ai_core.process_advanced_message(user_message, user_id)
        
        return jsonify({
            'response': result['message'],
            'analysis': result['analysis'],
            'model_loaded': MODEL_LOADED,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logging.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©: {e}")
        return jsonify({'error': 'Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©'}), 500

@app.route('/api/user/profile/<user_id>')
def get_user_profile(user_id):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    profile = ai_core.user_profiles.get(user_id, {})
    return jsonify({
        'profile': profile,
        'level': ai_core.get_user_level(user_id),
        'total_interactions': len(ai_core.conversation_memory)
    })

@app.route('/api/learning/path')
def get_learning_path():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± ØªØ¹Ù„Ù…"""
    topic = request.args.get('topic', 'Ø¨Ø±Ù…Ø¬Ø©')
    level = request.args.get('level', 'Ù…Ø¨ØªØ¯Ø¦')
    
    path = ai_core.generate_learning_path(topic, level)
    return jsonify({'learning_path': path})

@app.route('/api/project/idea')
def get_project_idea():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙÙƒØ±Ø© Ù…Ø´Ø±ÙˆØ¹"""
    field = request.args.get('field', 'Ø¨Ø±Ù…Ø¬Ø©')
    complexity = request.args.get('complexity', 'medium')
    
    idea = ai_core.generate_project_idea(field, complexity)
    return jsonify({'project_idea': idea})

@app.route('/health')
def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
    return jsonify({
        'status': 'running',
        'model_loaded': MODEL_LOADED,
        'version': 'elite_2.0.0',
        'timestamp': datetime.now().isoformat()
    })

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
